{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Tensor Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 0.0000e+00, 6.5497e+00],\n",
      "        [5.3670e-43, 0.0000e+00, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "#Tensor의 기초적 선언\n",
    "#torch.FloatTensor와 같음\n",
    "# x = torch.Tensor(행, 열)\n",
    "x = torch.Tensor(2, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Type :  <class 'torch.Tensor'>\n",
      "Tensor Type :  torch.FloatTensor\n",
      "Tensor Size :  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#Tesnor의 정보 확인\n",
    "print(\"Tensor Type : \", type(x))\n",
    "print(\"Tensor Type : \", x.type())\n",
    "print(\"Tensor Size : \", x.size()) # x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Tensor with charateristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "Tensor Type :  torch.FloatTensor\n",
      "Tensor Size :  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#0으로 채워진 Tensor 선언\n",
    "x = torch.zeros(2, 3)\n",
    "print(x)\n",
    "print(\"Tensor Type : \", x.type())\n",
    "print(\"Tensor Size : \", x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0]], dtype=torch.int32)\n",
      "Tensor Type :  torch.IntTensor\n",
      "Tensor Size :  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(2,3, dtype=torch.int32)\n",
    "print(x)\n",
    "print(\"Tensor Type : \", x.type())\n",
    "print(\"Tensor Size : \", x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "Tensor Type :  torch.FloatTensor\n",
      "Tensor Size :  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#1로 채워진 Tensor 선언\n",
    "x = torch.ones(2, 3)\n",
    "print(x)\n",
    "print(\"Tensor Type : \", x.type())\n",
    "print(\"Tensor Size : \", x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9676, 0.8235, 0.7496],\n",
      "        [0.2291, 0.8252, 0.9668]])\n",
      "Tensor Type :  torch.FloatTensor\n",
      "Tensor Size :  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#0, 1 사이의 랜덤 숫자로 채워진 Tensor 선언\n",
    "x = torch.rand(2, 3)\n",
    "print(x)\n",
    "print(\"Tensor Type : \", x.type())\n",
    "print(\"Tensor Size : \", x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3727,  0.8271,  0.4655],\n",
      "        [ 0.2175, -1.4507,  0.1203]])\n",
      "Tensor Type :  torch.FloatTensor\n",
      "Tensor Size :  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#평균이 0이고 분산이 1을 따르는 정규분포에서 추출된 값으로 채워진 Tensor 선언\n",
    "x = torch.randn(2, 3)\n",
    "print(x)\n",
    "print(\"Tensor Type : \", x.type())\n",
    "print(\"Tensor Size : \", x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.]])\n",
      "Tensor Type :  torch.FloatTensor\n",
      "Tensor Size :  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#정방행렬과 같은 Tensor 선언\n",
    "x = torch.eye(2, 3)\n",
    "print(x)\n",
    "print(\"Tensor Type : \", x.type())\n",
    "print(\"Tensor Size : \", x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.5000, 1.0000, 1.5000])\n",
      "Tensor Type :  torch.FloatTensor\n",
      "Tensor Size :  torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "#0부터 2까지 0.5씩 증가하는 Tensor 선언\n",
    "x = torch.arange(0, 2, step=0.5)\n",
    "print(x)\n",
    "print(\"Tensor Type : \", x.type())\n",
    "print(\"Tensor Size : \", x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [1., 2., 3.]])\n",
      "Tensor Type :  torch.FloatTensor\n",
      "Tensor Size :  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#직접 값을 입력하여 선언\n",
    "x = torch.Tensor([[1,2,3],[1,2,3]])\n",
    "print(x)\n",
    "print(\"Tensor Type : \", x.type())\n",
    "print(\"Tensor Size : \", x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-8.7051e+09,  4.5915e-41,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
      "Tensor Type :  torch.FloatTensor\n",
      "Tensor Size :  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#32-bit floating point\n",
    "x = torch.FloatTensor(2,3)\n",
    "print(x)\n",
    "print(\"Tensor Type : \", x.type())\n",
    "print(\"Tensor Size : \", x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-805193944,      32766,          0],\n",
      "        [         0,          0,          0]], dtype=torch.int32)\n",
      "Tensor Type :  torch.IntTensor\n",
      "Tensor Size :  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#32-bit integer (signed)\n",
    "x = torch.IntTensor(2,3)\n",
    "print(x)\n",
    "print(\"Tensor Type : \", x.type())\n",
    "print(\"Tensor Size : \", x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Tensor and Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [1 2 3]] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#numpy 형식의 배열\n",
    "x = np.array([[1,2,3],[1,2,3]])\n",
    "print(x, type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [1, 2, 3]], dtype=torch.int32)\n",
      "Tensor Type :  torch.IntTensor\n",
      "Tensor Size :  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#numpy를 tensor로 변환\n",
    "x = torch.from_numpy(x)\n",
    "print(x)\n",
    "print(\"Tensor Type : \", x.type())\n",
    "print(\"Tensor Size : \", x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [1 2 3]] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#tensor를 numpy로 변환\n",
    "x = x.numpy()\n",
    "print(x, type(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Tensor Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.,  4.],\n",
      "        [ 5.,  6.,  7.,  8.],\n",
      "        [ 9., 10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.],\n",
       "        [ 5.,  6.,  7.,  8.],\n",
       "        [ 9., 10., 11., 12.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모든 원소 출력\n",
    "x[:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  6.,  7.,  8.],\n",
       "        [ 9., 10., 11., 12.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2행부터 출력\n",
    "x[1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  3.,  4.],\n",
       "        [ 6.,  7.,  8.],\n",
       "        [10., 11., 12.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2열부터 출력\n",
    "x[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.,  7.],\n",
       "        [10., 11.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2행, 2열부터 3열까지 출력\n",
    "x[1:, 1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1행 출력\n",
    "x[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1., 2., 3., 4.]]), tensor([[5., 6., 7., 8.]]), tensor([[ 9., 10., 11., 12.]]))\n"
     ]
    }
   ],
   "source": [
    "#x를 1행씩 잘라서 배열로 저장\n",
    "x_rows = torch.split(x, split_size_or_sections=1, dim=0)\n",
    "print(x_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4.]]),\n",
       " tensor([[5., 6., 7., 8.]]),\n",
       " tensor([[ 9., 10., 11., 12.]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#위와 같은 결과\n",
    "torch.chunk(x, chunks=3, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 1.,  2.],\n",
      "        [ 5.,  6.],\n",
      "        [ 9., 10.]]), tensor([[ 3.,  4.],\n",
      "        [ 7.,  8.],\n",
      "        [11., 12.]]))\n"
     ]
    }
   ],
   "source": [
    "#x를 2열씩 잘라서 배열로 저장\n",
    "x_cols = torch.split(x, split_size_or_sections=2, dim=1)\n",
    "print(x_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.],\n",
       "         [ 5.,  6.],\n",
       "         [ 9., 10.]]), tensor([[ 3.,  4.],\n",
       "         [ 7.,  8.],\n",
       "         [11., 12.]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#위와 같은 결과\n",
    "torch.chunk(x, chunks=2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.,  5., 10.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_cols의 첫번째 배열 중 특정 부분만 추출하기\n",
    "torch.masked_select(x_cols[0], torch.ByteTensor([[0,1],[1,0],[0,1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Tensor Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.],\n",
       "        [ 5.,  6.,  7.,  8.],\n",
       "        [ 9., 10., 11., 12.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_rows를 행으로 이어 붙이기\n",
    "torch.cat(x_rows, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_rows를 열로 이어 붙이기\n",
    "torch.cat(x_rows, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.,  2.],\n",
      "         [ 5.,  6.],\n",
      "         [ 9., 10.]],\n",
      "\n",
      "        [[ 3.,  4.],\n",
      "         [ 7.,  8.],\n",
      "         [11., 12.]]])\n"
     ]
    }
   ],
   "source": [
    "#x_cols를 쌓아올리기\n",
    "x_new = torch.stack(x_cols, dim=0)\n",
    "print(x_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Tensor Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.,  4.],\n",
      "        [ 5.,  6.,  7.,  8.],\n",
      "        [ 9., 10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.],\n",
       "        [ 7.,  8.,  9.],\n",
       "        [10., 11., 12.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4행 3열로 바꾸기\n",
    "x.view(4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.],\n",
       "        [ 3.,  4.],\n",
       "        [ 5.,  6.],\n",
       "        [ 7.,  8.],\n",
       "        [ 9., 10.],\n",
       "        [11., 12.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2열로 바꾸기\n",
    "x.view(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  2.,  3.,  4.,  5.,  6.]],\n",
       "\n",
       "        [[ 7.,  8.,  9., 10., 11., 12.]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(2, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.],\n",
       "        [ 7.,  8.,  9., 10., 11., 12.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#차원이 1인 값을 축소\n",
    "x.view(2, 1, -1).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  2.,  3.,  4.,  5.,  6.]],\n",
       "\n",
       "        [[ 7.,  8.,  9., 10., 11., 12.]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dim=1 자리에 차원을 추가\n",
    "x.view(2, 1, -1).squeeze().unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Tensor for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [1., 2., 3.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,2,3],[1,2,3]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 Cuda 사용 가능한 Device 개수 : 1\n",
      "현재 Cuda 사용 가능 여부 : True\n",
      "현재 사용 중인 Cuda Device : 0\n",
      "현재 Cuda Device 이름 : GeForce GTX TITAN X\n",
      "현재 Cuda Device의 사용 가능한 메모리 : 0 bytes\n",
      "현재 Cuda Device의 사용 중인 메모리 : 0 bytes\n"
     ]
    }
   ],
   "source": [
    "# cuda 확인\n",
    "print(\"현재 Cuda 사용 가능한 Device 개수 :\", torch.cuda.device_count())\n",
    "print(\"현재 Cuda 사용 가능 여부 :\", torch.cuda.is_available())\n",
    "print(\"현재 사용 중인 Cuda Device :\", torch.cuda.current_device())\n",
    "print(\"현재 Cuda Device 이름 :\", torch.cuda.get_device_name(0))\n",
    "print(\"현재 Cuda Device의 사용 가능한 메모리 :\", torch.cuda.max_memory_allocated(device=0), \"bytes\")\n",
    "print(\"현재 Cuda Device의 사용 중인 메모리 :\", torch.cuda.memory_allocated(device=0), \"bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda 세팅\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [1., 2., 3.]], device='cuda:0')\n",
      "Tensor Type :  torch.cuda.FloatTensor\n",
      "Tensor Size :  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#cpu를 gpu로 전환\n",
    "gpu_x = x.cuda()\n",
    "print(gpu_x)\n",
    "print(\"Tensor Type : \", gpu_x.type())\n",
    "print(\"Tensor Size : \", gpu_x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [1., 2., 3.]], device='cuda:0')\n",
      "Tensor Type :  torch.cuda.FloatTensor\n",
      "Tensor Size :  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#cpu를 gpu로 전환 2\n",
    "device = torch.device(\"cuda\")\n",
    "gpu_x = x.to(device)\n",
    "print(gpu_x)\n",
    "print(\"Tensor Type : \", gpu_x.type())\n",
    "print(\"Tensor Size : \", gpu_x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [1., 2., 3.]])\n",
      "Tensor Type :  torch.FloatTensor\n",
      "Tensor Size :  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#gpu를 cpu로 전환\n",
    "x = gpu_x.cpu()\n",
    "print(x)\n",
    "print(\"Tensor Type : \", x.type())\n",
    "print(\"Tensor Size : \", x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [1., 2., 3.]])\n",
      "Tensor Type :  torch.FloatTensor\n",
      "Tensor Size :  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#gpu를 cpu로 전환 2\n",
    "device = torch.device(\"cpu\")\n",
    "x = gpu_x.to(device)\n",
    "print(x)\n",
    "print(\"Tensor Type : \", x.type())\n",
    "print(\"Tensor Size : \", x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected type torch.cuda.FloatTensor but got torch.FloatTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-8f59ed9ccba0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# gpu tensor와 cpu tensor의 연산\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgpu_x\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: expected type torch.cuda.FloatTensor but got torch.FloatTensor"
     ]
    }
   ],
   "source": [
    "# gpu tensor와 cpu tensor의 연산\n",
    "gpu_x + x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 Tensor Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "y : tensor([[1., 1., 1.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,2,3],[4,5,6]])\n",
    "y = torch.Tensor([[1,1,1],[2,2,2]])\n",
    "print(\"x :\", x)\n",
    "print(\"y :\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z : tensor([[2., 3., 4.],\n",
      "        [6., 7., 8.]])\n",
      "x+y : tensor([[2., 3., 4.],\n",
      "        [6., 7., 8.]])\n"
     ]
    }
   ],
   "source": [
    "# x와 y의 합\n",
    "z = torch.add(x, y)\n",
    "print(\"z :\", z)\n",
    "print(\"x+y :\", x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.,  0.,  1.],\n",
      "        [ 2.,  3.,  4.]])\n",
      "tensor([[ 2.,  4.,  6.],\n",
      "        [ 8., 10., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# x의 모든 원소에서 2를 뺌\n",
    "print(x - 2)\n",
    "\n",
    "# x의 모든 원소에 2를 곱함\n",
    "print(2*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z : tensor([[ 1.,  2.,  3.],\n",
      "        [ 8., 10., 12.]])\n",
      "x*y : tensor([[ 1.,  2.,  3.],\n",
      "        [ 8., 10., 12.]])\n"
     ]
    }
   ],
   "source": [
    "#x의 원소와 y의 원소를 각각 곱함\n",
    "z = torch.mul(x, y)\n",
    "print(\"z :\", z)\n",
    "print(\"x*y :\", x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z : tensor([[ 1.,  4.,  9.],\n",
      "        [16., 25., 36.]])\n",
      "x**2 : tensor([[ 1.,  4.,  9.],\n",
      "        [16., 25., 36.]])\n"
     ]
    }
   ],
   "source": [
    "#x의 원소를 각각 제곱함\n",
    "z = torch.pow(x, 2)\n",
    "print(\"z :\", z)\n",
    "print(\"x**2 :\", x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z : tensor([[0.0000, 0.6931, 1.0986],\n",
      "        [1.3863, 1.6094, 1.7918]])\n",
      "x.log() : tensor([[0.0000, 0.6931, 1.0986],\n",
      "        [1.3863, 1.6094, 1.7918]])\n"
     ]
    }
   ],
   "source": [
    "#x의 원소에 log를 씌움\n",
    "z = torch.log(x)\n",
    "print(\"z :\", z)\n",
    "print(\"x.log() :\", x.log())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z : tensor([[1.0000, 1.4142, 1.7321],\n",
      "        [2.0000, 2.2361, 2.4495]])\n",
      "x.sqrt() : tensor([[1.0000, 1.4142, 1.7321],\n",
      "        [2.0000, 2.2361, 2.4495]])\n"
     ]
    }
   ],
   "source": [
    "#x의 원소에 루트를 씌움\n",
    "z = torch.sqrt(x)\n",
    "print(\"z :\", z)\n",
    "print(\"x.sqrt() :\", x.sqrt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1.],\n",
      "        [0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "#x의 원소에 나머지(mod) 계산\n",
    "z = x % 2\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z : tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "x.abs() : tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "#x에 절댓값\n",
    "z = torch.abs(x)\n",
    "print(\"z :\", z)\n",
    "print(\"x.abs() :\", x.abs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9 Tensor Casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "y : tensor([[1., 1., 1.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,2,3],[4,5,6]])\n",
    "y = torch.Tensor([[1,1,1],[2,2,2]])\n",
    "print(\"x :\", x)\n",
    "print(\"y :\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.type(torch.DoubleTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]], dtype=torch.int32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.type(torch.IntTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]], dtype=torch.int32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.int()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.10 Tensor Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.,  2., -3.],\n",
      "        [ 4., -5.,  6.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[-1,2,-3],[4,-5,6]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x의 합 : tensor(3.)\n",
      "x의 최대값 : tensor(6.)\n",
      "x의 최소값 : tensor(-5.)\n",
      "x의 분산 : tensor(17.9000)\n"
     ]
    }
   ],
   "source": [
    "print(\"x의 합 :\", x.sum())\n",
    "print(\"x의 최대값 :\", x.max())\n",
    "print(\"x의 최소값 :\", x.min())\n",
    "print(\"x의 분산 :\", x.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar Tensor\n",
    "x.sum().size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x의 합 : 3.0\n",
      "x의 최대값 : 6.0\n",
      "x의 최소값 : -5.0\n",
      "x의 분산 : 17.899999618530273\n"
     ]
    }
   ],
   "source": [
    "# item의 활용\n",
    "print(\"x의 합 :\", x.sum().item())\n",
    "print(\"x의 최대값 :\", x.max().item())\n",
    "print(\"x의 최소값 :\", x.min().item())\n",
    "print(\"x의 분산 :\", x.var().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 2., 6.])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#행을 기준으로 열의 최댓값을 출력\n",
    "value, index = x.max(dim=0)\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3., -1.,  2.],\n",
       "        [-5.,  4.,  6.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#열을 기준으로 각 행을 정렬\n",
    "value, index = x.sort(dim=1)\n",
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.11 Tensor *_like function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.,  2., -3.],\n",
      "        [ 4., -5.,  6.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[-1,2,-3],[4,-5,6]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.zeros_like(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.ones_like(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9878, 0.4228, 0.4301],\n",
      "        [0.3012, 0.7606, 0.2999]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand_like(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.12 Tensor Calculation as Matrix (참고)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : tensor([[1., 1.],\n",
      "        [2., 2.]])\n",
      "y : tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,1],[2,2]])\n",
    "y = torch.Tensor([[1,2],[3,4]])\n",
    "print(\"x :\", x)\n",
    "print(\"y :\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  6.],\n",
       "        [ 8., 12.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x와 y의 행렬곱\n",
    "torch.mm(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6.])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x와 z의 행렬벡터곱\n",
    "z = torch.Tensor([1, 2])\n",
    "torch.mv(x, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#z와 z의 내적\n",
    "torch.dot(z, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [1., 2.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x의 전치(transpose)\n",
    "x.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0000,  1.0000],\n",
       "        [ 1.5000, -0.5000]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y의 역행렬(inverse)\n",
    "y.inverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 3])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텐서의 배치 행렬곱\n",
    "x1 = torch.FloatTensor(3,3,2)\n",
    "x2 = torch.FloatTensor(3,2,3)\n",
    "\n",
    "torch.bmm(x1,x2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00],\n",
       "         [2.2701e-42, 0.0000e+00]],\n",
       "\n",
       "        [[0.0000e+00, 5.3670e-43],\n",
       "         [0.0000e+00, 0.0000e+00],\n",
       "         [7.0065e-45, 0.0000e+00]]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 2.2701e-42, 7.0065e-45]],\n",
       "\n",
       "        [[0.0000e+00, 0.0000e+00, 5.3670e-43],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00]]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텐서의 전치\n",
    "x1.transpose(0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalue : tensor([[1.1921e-07, 0.0000e+00],\n",
      "        [3.0000e+00, 0.0000e+00]])\n",
      "eigenvector : tensor([[-0.7071, -0.4472],\n",
      "        [ 0.7071, -0.8944]])\n"
     ]
    }
   ],
   "source": [
    "eigenvalue, eigenvector = torch.eig(x,eigenvectors=True)\n",
    "print(\"eigenvalue :\", eigenvalue)\n",
    "print(\"eigenvector :\", eigenvector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : tensor([[-0.4472, -0.8944],\n",
      "        [-0.8944,  0.4472]])\n",
      "R : tensor([[-2.2361e+00, -2.2361e+00],\n",
      "        [ 0.0000e+00,  1.1921e-07]])\n"
     ]
    }
   ],
   "source": [
    "#행렬의 QR factorization\n",
    "Q,R = torch.qr(x)\n",
    "print(\"Q :\", Q)\n",
    "print(\"R :\", R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S : tensor([[-0.4472, -0.8944],\n",
      "        [-0.8944,  0.4472]])\n",
      "V : tensor([3.1623e+00, 8.4294e-08])\n",
      "D : tensor([[-0.7071, -0.7071],\n",
      "        [-0.7071,  0.7071]])\n"
     ]
    }
   ],
   "source": [
    "#행렬의 SVD factorization\n",
    "S,V,D = torch.svd(x)\n",
    "print(\"S :\", S)\n",
    "print(\"V :\", V)\n",
    "print(\"D :\", D)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
