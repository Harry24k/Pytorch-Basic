{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 24. Variational AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.init\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.utils as utils\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24.1 Preparing MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = dsets.MNIST(root='data/',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "train_loader  = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=mnist_test,\n",
    "                                         batch_size=1,\n",
    "                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, title):\n",
    "    npimg = img.numpy()\n",
    "    fig = plt.figure(figsize = (5, 15))\n",
    "    plt.imshow(np.transpose(npimg,(1,2,0)))\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "images, labels = iter(train_loader).next()\n",
    "imshow(torchvision.utils.make_grid(images, normalize=True), \"Train Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24.2 Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1,16,5),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Conv2d(16,32,5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32,64,5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2) #64*3*3\n",
    "        )\n",
    "        \n",
    "        self.f_mu = nn.Sequential(\n",
    "            nn.Linear(64*3*3, 200),\n",
    "            nn.Linear(200, 50)\n",
    "        )\n",
    "        \n",
    "        self.f_std_log = nn.Sequential(\n",
    "            nn.Linear(64*3*3, 200),\n",
    "            nn.Linear(200, 50)\n",
    "        )\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight.data)\n",
    "                m.bias.data.fill_(0)\n",
    "        \n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight.data)\n",
    "                m.bias.data.fill_(0)                \n",
    "        \n",
    "    def encode(self, x) :\n",
    "        out = self.encoder(x)\n",
    "        out = out.view(-1, 64*3*3)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        mu = self.f_mu(out)\n",
    "        std_log = self.f_std_log(out)\n",
    "        \n",
    "        return mu, std_log\n",
    "        \n",
    "    def f_latent(self, mu, std_log) :\n",
    "        if self.training :\n",
    "\n",
    "            std = std_log.exp()\n",
    "\n",
    "            eps = torch.randn_like(std)\n",
    "            eps = eps.cuda()\n",
    "\n",
    "            z = eps * std + mu\n",
    "\n",
    "            return z\n",
    "\n",
    "        else :\n",
    "            return mu\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mu, std_log = self.encode(x)\n",
    "        z = self.f_latent(mu, std_log)\n",
    "        \n",
    "        return mu, std_log, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(50, 200),\n",
    "            nn.Linear(200, 64*3*3)\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64,32,5,stride=2,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ConvTranspose2d(32,16,4,stride=2,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ConvTranspose2d(16,1,4,stride=2,padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, z):\n",
    "        out = self.fc(z)\n",
    "        out = out.view(-1,64,3,3)\n",
    "        out = self.decoder(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = Encoder().cuda()\n",
    "D = Decoder().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22.3 Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_loss = nn.BCELoss(reduction='sum')\n",
    "\n",
    "def KLD_loss(mu, std_log) :\n",
    "    var_log = 2*std_log\n",
    "    return torch.sum(var_log.exp() + mu.pow(2) - 1 - var_log)/2\n",
    "\n",
    "optimizer = optim.Adam(list(E.parameters()) + list(D.parameters()), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    total_batch = len(mnist_train) // batch_size\n",
    "    \n",
    "    for i, (batch_images, batch_labels) in enumerate(train_loader):\n",
    "        \n",
    "        X = batch_images.cuda()\n",
    "        \n",
    "        mu, std_log, z = E(X)\n",
    "        pre = D(z)\n",
    "        \n",
    "        cost = reconstruction_loss(pre, X) + KLD_loss(mu, std_log)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch [%d/%d], lter [%d/%d], Loss: %.4f'\n",
    "                 %(epoch+1, num_epochs, i+1, total_batch, cost.item()))\n",
    "    \n",
    "print(\"Learning Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22.4 Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "E.eval()\n",
    "D.eval()\n",
    "\n",
    "for n, (images, labels) in enumerate(mnist_test):\n",
    "    \n",
    "    imshow(torchvision.utils.make_grid(images, normalize=True), \"Input Image\")\n",
    "    images = images.view(-1, 1, 28, 28).cuda()\n",
    "    \n",
    "    mu, std_log, z = E(images)\n",
    "    outputs = D(z)\n",
    "    \n",
    "    imshow(torchvision.utils.make_grid(outputs.data.cpu(), normalize=True), \"Output Image\")\n",
    "    \n",
    "    if n > 2 : break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
