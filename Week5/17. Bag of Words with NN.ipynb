{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17. Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "import random\n",
    "import codecs\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.1 Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# G마켓에 좋은 평만 있어서 사봤는데.. 정말 진짜 진짜 사지마세요. 개. 쓰. 레. 기 (진심) 입니다. 액정부터 짜증나는 TN패널에, 하드 SSD인걸로 알았는데, 속도는 저질 SD카드 꽂아 놓은것 같습니다. 정말 느려터집니다. 저는 단지 인터넷 뱅킹만 할려고, 샀단 말입니다. 그런데 인터넷 뱅킹 프로그램까는데만 10~20분 걸립니다. 뭐약!! 이게!! 분노로 인해 볼때마다 짜증납니다. 밤에 잠도 안오고요.. 사시면 분명 후회하실겁니다. 아! 진짜 G마켓 프리미엄평으로 실날하게 사진찍어서 올리려고했는데, 먹고 산다고 바빠서 프리미엄 평 못 올린게 정말 천추의 한이네요!!\\n# 원래 그런 줄 알고 사는 \"저가 제품\"이라고 생각합니다만. IPS라는 언급이 없으니 당연히 TN 패널일 테고, EMMC는 SSD가 아니고 SD 카드 내장된 것 같은 것이라 원래 SSD보다 느린 것이고, CPU도 아톰이니 뭐 당연히 느리죠. 그런 것 다 감안하고 \"싸고 가볍다\"는 조건으로 사는 제품인데요. 뭐 '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = codecs.open(\"data/reviews.txt\", 'r', 'utf-8')\n",
    "f.read()[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.2 Extract Setences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"발열\", \"소음\"]\n",
    "\n",
    "for keyword in keywords :\n",
    "    temp_list = []\n",
    "    save_name = \"data/reviews_\" + keyword + \".txt\"\n",
    "    f = codecs.open(\"data/reviews.txt\", 'r', 'utf-8')\n",
    "    t = codecs.open(save_name, 'w', 'utf-8')\n",
    "    \n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line: break\n",
    "        if keyword in line :\n",
    "            temp_list.append(line)\n",
    "            \n",
    "    set_list = list(set(temp_list))\n",
    "    \n",
    "    for item in set_list :\n",
    "        t.write(item)\n",
    "        \n",
    "    f.close()\n",
    "    t.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# 화면이 작을까봐 14인치랑 굉장히 고민 많이했는데... 제 선택이 맞았네요.저는 매일 가지고 다녀야 해서 휴대성을 가장 크게 보고 골랐는데요.화면도 고민했던 것 처럼 작지 않고 좋습니다!!무게는 말할 것도 없이 정말 가볍고 얇아요~!! 디자인, 휴대성... 뭐 하나 빠지는 게 없네요. 윈도우도 깔려 있어서 더 좋습니다^^ 발열도 심하지 않고, 자판도 편해요.다만 숫자키가 옆에 없어서 아쉽지만, 작은 사이즈는 어쩔 수 없으니까요~암튼 완전 만족입니당~^^\\n# 여기 이삼성노트북 첫번째는 동생한테가게되서, 삼성노트북 두번째 구입하게 되었고, 현재저렴하면서 작은거 웬만큼 쓸만한거 삼성 엘지(텝북은너무비싸구)제품 중에는 이삼성노트북밖에없습니다더욱이 브라스웰제품 중에는 유일하죠 (4GB128GB) , 자정리하자면 화면 야외서보는데지장없고, 인터넷동영상하는데 지장없고사운드좋구요, 소음이없고 오랜시간써도 발열이거의없기에 도서관 자료검색 인강용으로 가성비최고가 아닐까 하는 생각이 듭니다.물론 돈'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = codecs.open(\"data/reviews_발열.txt\", 'r', 'utf-8')\n",
    "f.read()[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.3 Load Scored Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data/score_발열.xlsx\"\n",
    "sheet_name = \"Sheet1\"\n",
    "data = pd.read_excel(filename, sheet_name = sheet_name, header = 0)\n",
    "\n",
    "csv_data = [item.replace(\"#\", \"\").strip() for item in data['Review']]\n",
    "csv_label = data['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['발열히 심한거 같은데 여름이라 그런가?..',\n",
       " '발열이좀 심한거 같아서 걱정이에요',\n",
       " '발열이심하더라구요',\n",
       " '발열이너무심한게 제일큰 단점인것 같고 그외에 불편한점은',\n",
       " '발열이...정말...심합니다']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = [sum(csv_label == 0), sum(csv_label == 1), sum(csv_label == 2)]\n",
    "plt.bar(range(len(scores)),scores, color=\"#ff5733\")\n",
    "\n",
    "plt.title(\"Average Laptop's Score of Heat\")\n",
    "plt.xlabel(\"Heat Score\")\n",
    "plt.ylabel(\"Reviews\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.4 Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/jpype/_core.py:210: UserWarning: \n",
      "-------------------------------------------------------------------------------\n",
      "Deprecated: convertStrings was not specified when starting the JVM. The default\n",
      "behavior in JPype will be False starting in JPype 0.8. The recommended setting\n",
      "for new code is convertStrings=False.  The legacy value of True was assumed for\n",
      "this session. If you are a user of an application that reported this warning,\n",
      "please file a ticket with the developer.\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Okt()\n",
    "doc = []\n",
    "\n",
    "for sentence in csv_data :\n",
    "    results= []\n",
    "    tokens = tokenizer.pos(sentence, norm=True, stem=True)\n",
    "        \n",
    "    for token in tokens:\n",
    "        if not token[1] in [\"Josa\", \"Eomi\", \"Punctuation\"]:\n",
    "            results.append(token[0])\n",
    "    doc.append(\" \".join(results).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['발열 히 심하다 같다 여름 그 런가',\n",
       " '발열 이 좀 심하다 같다 걱정',\n",
       " '발열 심하다',\n",
       " '발열 이 너 무심하다 제일 크다 단점 것 같다 그 외 불편하다 점',\n",
       " '발열 정말 심하다']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer\n",
    "cnv = CountVectorizer(ngram_range=(1,1), min_df = 3)\n",
    "\n",
    "data = cnv.fit_transform(doc).toarray()\n",
    "label = csv_label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorizer\n",
    "# tfidv = TfidfVectorizer().fit(data)\n",
    "# data = tfidv.transform(data).toarray()\n",
    "\n",
    "# data = pd.DataFrame(data)\n",
    "# data = (data - data.mean()) / (data.max() - data.min() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'발열': 112,\n",
       " '심하다': 156,\n",
       " '같다': 13,\n",
       " '여름': 187,\n",
       " '걱정': 16,\n",
       " '무심하다': 104,\n",
       " '크다': 266,\n",
       " '단점': 57,\n",
       " '불편하다': 125,\n",
       " '정말': 237,\n",
       " '확실하다': 292,\n",
       " '심해': 157,\n",
       " '노트북': 45,\n",
       " '쿨러': 263,\n",
       " '사용': 134,\n",
       " '크게': 265,\n",
       " '진짜': 250,\n",
       " '너무': 43,\n",
       " '많이': 93,\n",
       " '있다': 218,\n",
       " '장시간': 228,\n",
       " '높다': 47,\n",
       " '프로그램': 275,\n",
       " '한편': 283,\n",
       " '이다': 204,\n",
       " '심다': 155,\n",
       " '밧데리': 113,\n",
       " 'cpu': 4,\n",
       " '용량': 200,\n",
       " '빼다': 131,\n",
       " '괜찮다': 22,\n",
       " '느낌': 50,\n",
       " '하지만': 281,\n",
       " '자판': 221,\n",
       " '조금': 241,\n",
       " '속도': 149,\n",
       " '매우': 94,\n",
       " '좋다': 244,\n",
       " '이전': 211,\n",
       " '하다': 279,\n",
       " '뜨겁다': 83,\n",
       " '가볍다': 10,\n",
       " '조용하다': 242,\n",
       " '마음': 88,\n",
       " '듭니': 72,\n",
       " '돌아가다': 65,\n",
       " '불량': 124,\n",
       " '심해지다': 158,\n",
       " '생기다': 141,\n",
       " '소리': 147,\n",
       " '나다': 38,\n",
       " '그렇다': 31,\n",
       " '부분': 122,\n",
       " '문제': 107,\n",
       " '끊기다': 37,\n",
       " '쓰다': 160,\n",
       " '약간': 175,\n",
       " '게임': 18,\n",
       " '돌리다': 64,\n",
       " '정도': 236,\n",
       " '성능': 145,\n",
       " '라면': 85,\n",
       " '지다': 249,\n",
       " '이렇다': 206,\n",
       " '부팅': 123,\n",
       " '화상': 289,\n",
       " '원래': 202,\n",
       " '모르다': 100,\n",
       " '않다': 171,\n",
       " '구매': 24,\n",
       " '신분': 154,\n",
       " '야하다': 174,\n",
       " '제외': 239,\n",
       " '자주': 220,\n",
       " '발생': 111,\n",
       " '삼성': 137,\n",
       " '소음': 148,\n",
       " '치다': 259,\n",
       " '만족하다': 91,\n",
       " '배터리': 116,\n",
       " '빠르다': 128,\n",
       " '무엇': 105,\n",
       " '생각': 140,\n",
       " '하드': 280,\n",
       " '보드': 119,\n",
       " '왼쪽': 199,\n",
       " '상당하다': 138,\n",
       " '살짝': 136,\n",
       " '메탈': 95,\n",
       " '비다': 126,\n",
       " '비추다': 127,\n",
       " '휴대': 294,\n",
       " '다니다': 54,\n",
       " '많다': 92,\n",
       " '느리다': 51,\n",
       " '다른': 55,\n",
       " '제품': 240,\n",
       " '시간': 152,\n",
       " '센터': 146,\n",
       " '늘다': 52,\n",
       " '이제': 213,\n",
       " '조절': 243,\n",
       " '약하다': 176,\n",
       " '어쩔': 182,\n",
       " '전혀': 233,\n",
       " '잡지': 226,\n",
       " '해보다': 284,\n",
       " '편이': 271,\n",
       " '되다': 67,\n",
       " '화이트': 290,\n",
       " '다소': 56,\n",
       " '느껴지다': 48,\n",
       " '하나': 277,\n",
       " '따르다': 77,\n",
       " '내다': 42,\n",
       " '사양': 133,\n",
       " '낮다': 41,\n",
       " '양호': 178,\n",
       " '상태': 139,\n",
       " '차이': 253,\n",
       " '보다': 118,\n",
       " '수가': 150,\n",
       " '없다': 185,\n",
       " '인하다': 215,\n",
       " '지금': 248,\n",
       " '어떻다': 181,\n",
       " '또한': 81,\n",
       " '가격': 8,\n",
       " '때문': 79,\n",
       " '켜다': 262,\n",
       " '충전': 258,\n",
       " '능력': 53,\n",
       " '떨어지다': 80,\n",
       " '오래되다': 194,\n",
       " '자다': 219,\n",
       " '관리': 21,\n",
       " '돼다': 66,\n",
       " '걸리다': 17,\n",
       " '아니다': 163,\n",
       " '안되다': 169,\n",
       " '그냥': 26,\n",
       " '받침': 110,\n",
       " '절대': 234,\n",
       " '보이다': 120,\n",
       " '고민': 20,\n",
       " '빠지다': 130,\n",
       " '모두': 98,\n",
       " '한성': 282,\n",
       " '구성': 25,\n",
       " 'as': 3,\n",
       " '굉장하다': 23,\n",
       " '깔끔하다': 36,\n",
       " '이쁘다': 208,\n",
       " '모델': 97,\n",
       " '현상': 286,\n",
       " '50': 1,\n",
       " '준수': 246,\n",
       " '처리': 254,\n",
       " '잡다': 225,\n",
       " '얇다': 177,\n",
       " '오래': 193,\n",
       " '쓸다': 162,\n",
       " '일이': 217,\n",
       " '인터넷': 214,\n",
       " '100': 0,\n",
       " '그래픽': 28,\n",
       " '장점': 229,\n",
       " '훨씬': 293,\n",
       " '해소': 285,\n",
       " '패드': 269,\n",
       " '일어나서': 216,\n",
       " '쿨링': 264,\n",
       " '이상': 209,\n",
       " '기본': 35,\n",
       " '서비스': 142,\n",
       " '들다': 71,\n",
       " '사은': 135,\n",
       " '주다': 245,\n",
       " '어느': 180,\n",
       " '문서': 106,\n",
       " '작업': 223,\n",
       " '편입': 272,\n",
       " '아주': 166,\n",
       " '컴퓨터': 261,\n",
       " '배송': 115,\n",
       " '이정': 212,\n",
       " '무게': 102,\n",
       " '그램': 29,\n",
       " '두다': 69,\n",
       " '온도': 195,\n",
       " '아쉽다': 164,\n",
       " '그래도': 27,\n",
       " '예쁘다': 191,\n",
       " '따다': 75,\n",
       " '안나': 168,\n",
       " '디자인': 74,\n",
       " '가다': 9,\n",
       " '편하다': 273,\n",
       " '겨울': 19,\n",
       " '이면': 207,\n",
       " '나쁘다': 39,\n",
       " '필요': 276,\n",
       " '받다': 109,\n",
       " '액정': 173,\n",
       " '돌다': 63,\n",
       " '아예': 165,\n",
       " '레노버': 86,\n",
       " '처음': 255,\n",
       " '써다': 159,\n",
       " '얘기': 179,\n",
       " '느끼다': 49,\n",
       " '나오다': 40,\n",
       " '등등': 73,\n",
       " '데스크탑': 62,\n",
       " '연결': 189,\n",
       " '아직': 167,\n",
       " '수준': 151,\n",
       " '뜨다': 84,\n",
       " '사다': 132,\n",
       " '설치': 144,\n",
       " '평소': 274,\n",
       " '70': 2,\n",
       " '신경': 153,\n",
       " '쓰이다': 161,\n",
       " '노트': 44,\n",
       " '따뜻하다': 76,\n",
       " '최고': 256,\n",
       " 'ssd': 6,\n",
       " '카드': 260,\n",
       " '마감': 87,\n",
       " '없이': 186,\n",
       " '윈도우': 203,\n",
       " '보통': 121,\n",
       " '펴다': 270,\n",
       " '감다': 12,\n",
       " '별로': 117,\n",
       " '화면': 288,\n",
       " 'ㅜㅜ': 7,\n",
       " '엄청': 183,\n",
       " '개선': 14,\n",
       " '차다': 252,\n",
       " '완벽하다': 196,\n",
       " '열량': 190,\n",
       " '빠릿빠릿': 129,\n",
       " '그렇게': 30,\n",
       " '기능': 33,\n",
       " '오다': 192,\n",
       " '모니터': 96,\n",
       " '적당하다': 232,\n",
       " '던지다': 61,\n",
       " '거의': 15,\n",
       " '무겁다': 101,\n",
       " '추천': 257,\n",
       " '만족': 89,\n",
       " '그리다': 32,\n",
       " '대다': 58,\n",
       " '대비': 60,\n",
       " '딱하다': 78,\n",
       " '뒤틀리다': 70,\n",
       " '짧다': 251,\n",
       " '모든': 99,\n",
       " '제어': 238,\n",
       " '완전': 197,\n",
       " '기다': 34,\n",
       " '알다': 172,\n",
       " '가성': 11,\n",
       " '잡히다': 227,\n",
       " '우수하다': 201,\n",
       " '증상': 247,\n",
       " '뛰어나다': 82,\n",
       " '되어다': 68,\n",
       " '적다': 231,\n",
       " '선택': 143,\n",
       " '만족스럽다': 90,\n",
       " '현재': 287,\n",
       " '화질': 291,\n",
       " '특히': 267,\n",
       " '하니': 278,\n",
       " '이렇게': 205,\n",
       " '놀라다': 46,\n",
       " '점수': 235,\n",
       " '물론': 108,\n",
       " '무리': 103,\n",
       " '외관': 198,\n",
       " '대단하다': 59,\n",
       " '역시': 188,\n",
       " '작다': 222,\n",
       " '저렴하다': 230,\n",
       " '잡고': 224,\n",
       " '엄청나다': 184,\n",
       " 'ips': 5,\n",
       " '패널': 268,\n",
       " '안심': 170,\n",
       " '배그': 114,\n",
       " '이슈': 210}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnv.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.5 Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = len(cnv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "908\n",
      "303\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data, train_label, test_label = train_test_split(data, label, stratify = label)\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(train_data).type(torch.FloatTensor)\n",
    "y = torch.from_numpy(train_label).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([908]), torch.Size([908, 295]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size() , x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(x, y)\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "train_loader  = DataLoader(dataset=train_data,\n",
    "                           batch_size=batch_size,\n",
    "                           shuffle=True,\n",
    "                           num_workers=1,\n",
    "                           drop_last = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.6 Define and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1 = nn.Linear(dim, 200, bias = True)\n",
    "linear2 = nn.Linear(200, 3, bias = True)\n",
    "relu = nn.ReLU()\n",
    "\n",
    "model = nn.Sequential(linear1, relu, linear2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], lter [20/90], Loss: 0.9148\n",
      "Epoch [1/50], lter [40/90], Loss: 0.8863\n",
      "Epoch [1/50], lter [60/90], Loss: 0.6495\n",
      "Epoch [1/50], lter [80/90], Loss: 0.7840\n",
      "Epoch [2/50], lter [20/90], Loss: 0.4797\n",
      "Epoch [2/50], lter [40/90], Loss: 0.6357\n",
      "Epoch [2/50], lter [60/90], Loss: 0.6474\n",
      "Epoch [2/50], lter [80/90], Loss: 1.0916\n",
      "Epoch [3/50], lter [20/90], Loss: 0.9933\n",
      "Epoch [3/50], lter [40/90], Loss: 0.7154\n",
      "Epoch [3/50], lter [60/90], Loss: 0.3200\n",
      "Epoch [3/50], lter [80/90], Loss: 0.4253\n",
      "Epoch [4/50], lter [20/90], Loss: 0.0941\n",
      "Epoch [4/50], lter [40/90], Loss: 0.2851\n",
      "Epoch [4/50], lter [60/90], Loss: 0.1472\n",
      "Epoch [4/50], lter [80/90], Loss: 0.3241\n",
      "Epoch [5/50], lter [20/90], Loss: 0.2410\n",
      "Epoch [5/50], lter [40/90], Loss: 0.2816\n",
      "Epoch [5/50], lter [60/90], Loss: 0.8152\n",
      "Epoch [5/50], lter [80/90], Loss: 0.3003\n",
      "Epoch [6/50], lter [20/90], Loss: 0.0499\n",
      "Epoch [6/50], lter [40/90], Loss: 0.2037\n",
      "Epoch [6/50], lter [60/90], Loss: 0.0628\n",
      "Epoch [6/50], lter [80/90], Loss: 0.3265\n",
      "Epoch [7/50], lter [20/90], Loss: 0.0612\n",
      "Epoch [7/50], lter [40/90], Loss: 0.1108\n",
      "Epoch [7/50], lter [60/90], Loss: 0.0852\n",
      "Epoch [7/50], lter [80/90], Loss: 0.1465\n",
      "Epoch [8/50], lter [20/90], Loss: 0.2063\n",
      "Epoch [8/50], lter [40/90], Loss: 0.3437\n",
      "Epoch [8/50], lter [60/90], Loss: 0.1623\n",
      "Epoch [8/50], lter [80/90], Loss: 0.0930\n",
      "Epoch [9/50], lter [20/90], Loss: 0.1620\n",
      "Epoch [9/50], lter [40/90], Loss: 0.1877\n",
      "Epoch [9/50], lter [60/90], Loss: 0.0676\n",
      "Epoch [9/50], lter [80/90], Loss: 0.3909\n",
      "Epoch [10/50], lter [20/90], Loss: 0.1074\n",
      "Epoch [10/50], lter [40/90], Loss: 0.0440\n",
      "Epoch [10/50], lter [60/90], Loss: 0.1278\n",
      "Epoch [10/50], lter [80/90], Loss: 0.0604\n",
      "Epoch [11/50], lter [20/90], Loss: 0.0114\n",
      "Epoch [11/50], lter [40/90], Loss: 0.0381\n",
      "Epoch [11/50], lter [60/90], Loss: 0.1372\n",
      "Epoch [11/50], lter [80/90], Loss: 0.1865\n",
      "Epoch [12/50], lter [20/90], Loss: 0.4934\n",
      "Epoch [12/50], lter [40/90], Loss: 0.0633\n",
      "Epoch [12/50], lter [60/90], Loss: 0.0698\n",
      "Epoch [12/50], lter [80/90], Loss: 0.2978\n",
      "Epoch [13/50], lter [20/90], Loss: 0.0096\n",
      "Epoch [13/50], lter [40/90], Loss: 0.3494\n",
      "Epoch [13/50], lter [60/90], Loss: 0.0986\n",
      "Epoch [13/50], lter [80/90], Loss: 0.0829\n",
      "Epoch [14/50], lter [20/90], Loss: 0.0251\n",
      "Epoch [14/50], lter [40/90], Loss: 0.0316\n",
      "Epoch [14/50], lter [60/90], Loss: 0.0073\n",
      "Epoch [14/50], lter [80/90], Loss: 0.0194\n",
      "Epoch [15/50], lter [20/90], Loss: 0.0159\n",
      "Epoch [15/50], lter [40/90], Loss: 0.1158\n",
      "Epoch [15/50], lter [60/90], Loss: 0.1602\n",
      "Epoch [15/50], lter [80/90], Loss: 0.0908\n",
      "Epoch [16/50], lter [20/90], Loss: 0.0658\n",
      "Epoch [16/50], lter [40/90], Loss: 0.1534\n",
      "Epoch [16/50], lter [60/90], Loss: 0.0828\n",
      "Epoch [16/50], lter [80/90], Loss: 0.0741\n",
      "Epoch [17/50], lter [20/90], Loss: 0.1293\n",
      "Epoch [17/50], lter [40/90], Loss: 0.1893\n",
      "Epoch [17/50], lter [60/90], Loss: 0.0224\n",
      "Epoch [17/50], lter [80/90], Loss: 0.0064\n",
      "Epoch [18/50], lter [20/90], Loss: 0.0400\n",
      "Epoch [18/50], lter [40/90], Loss: 0.0111\n",
      "Epoch [18/50], lter [60/90], Loss: 0.1485\n",
      "Epoch [18/50], lter [80/90], Loss: 0.0042\n",
      "Epoch [19/50], lter [20/90], Loss: 0.0124\n",
      "Epoch [19/50], lter [40/90], Loss: 0.1111\n",
      "Epoch [19/50], lter [60/90], Loss: 0.1447\n",
      "Epoch [19/50], lter [80/90], Loss: 0.0242\n",
      "Epoch [20/50], lter [20/90], Loss: 0.2589\n",
      "Epoch [20/50], lter [40/90], Loss: 0.0802\n",
      "Epoch [20/50], lter [60/90], Loss: 0.0129\n",
      "Epoch [20/50], lter [80/90], Loss: 0.0800\n",
      "Epoch [21/50], lter [20/90], Loss: 0.1475\n",
      "Epoch [21/50], lter [40/90], Loss: 0.1007\n",
      "Epoch [21/50], lter [60/90], Loss: 0.0536\n",
      "Epoch [21/50], lter [80/90], Loss: 0.0559\n",
      "Epoch [22/50], lter [20/90], Loss: 0.0267\n",
      "Epoch [22/50], lter [40/90], Loss: 0.0038\n",
      "Epoch [22/50], lter [60/90], Loss: 0.0584\n",
      "Epoch [22/50], lter [80/90], Loss: 0.1046\n",
      "Epoch [23/50], lter [20/90], Loss: 0.1718\n",
      "Epoch [23/50], lter [40/90], Loss: 0.1051\n",
      "Epoch [23/50], lter [60/90], Loss: 0.1192\n",
      "Epoch [23/50], lter [80/90], Loss: 0.1237\n",
      "Epoch [24/50], lter [20/90], Loss: 0.0197\n",
      "Epoch [24/50], lter [40/90], Loss: 0.0038\n",
      "Epoch [24/50], lter [60/90], Loss: 0.1014\n",
      "Epoch [24/50], lter [80/90], Loss: 0.0112\n",
      "Epoch [25/50], lter [20/90], Loss: 0.0169\n",
      "Epoch [25/50], lter [40/90], Loss: 0.0931\n",
      "Epoch [25/50], lter [60/90], Loss: 0.0580\n",
      "Epoch [25/50], lter [80/90], Loss: 0.1538\n",
      "Epoch [26/50], lter [20/90], Loss: 0.0060\n",
      "Epoch [26/50], lter [40/90], Loss: 0.2709\n",
      "Epoch [26/50], lter [60/90], Loss: 0.0934\n",
      "Epoch [26/50], lter [80/90], Loss: 0.0215\n",
      "Epoch [27/50], lter [20/90], Loss: 0.0890\n",
      "Epoch [27/50], lter [40/90], Loss: 0.1019\n",
      "Epoch [27/50], lter [60/90], Loss: 0.1777\n",
      "Epoch [27/50], lter [80/90], Loss: 0.0056\n",
      "Epoch [28/50], lter [20/90], Loss: 0.2573\n",
      "Epoch [28/50], lter [40/90], Loss: 0.0184\n",
      "Epoch [28/50], lter [60/90], Loss: 0.0113\n",
      "Epoch [28/50], lter [80/90], Loss: 0.0377\n",
      "Epoch [29/50], lter [20/90], Loss: 0.0006\n",
      "Epoch [29/50], lter [40/90], Loss: 0.0074\n",
      "Epoch [29/50], lter [60/90], Loss: 0.0746\n",
      "Epoch [29/50], lter [80/90], Loss: 0.0066\n",
      "Epoch [30/50], lter [20/90], Loss: 0.2691\n",
      "Epoch [30/50], lter [40/90], Loss: 0.0168\n",
      "Epoch [30/50], lter [60/90], Loss: 0.1554\n",
      "Epoch [30/50], lter [80/90], Loss: 0.1359\n",
      "Epoch [31/50], lter [20/90], Loss: 0.0222\n",
      "Epoch [31/50], lter [40/90], Loss: 0.0092\n",
      "Epoch [31/50], lter [60/90], Loss: 0.0077\n",
      "Epoch [31/50], lter [80/90], Loss: 0.1155\n",
      "Epoch [32/50], lter [20/90], Loss: 0.0508\n",
      "Epoch [32/50], lter [40/90], Loss: 0.0024\n",
      "Epoch [32/50], lter [60/90], Loss: 0.0016\n",
      "Epoch [32/50], lter [80/90], Loss: 0.0057\n",
      "Epoch [33/50], lter [20/90], Loss: 0.0050\n",
      "Epoch [33/50], lter [40/90], Loss: 0.0156\n",
      "Epoch [33/50], lter [60/90], Loss: 0.1360\n",
      "Epoch [33/50], lter [80/90], Loss: 0.0031\n",
      "Epoch [34/50], lter [20/90], Loss: 0.0056\n",
      "Epoch [34/50], lter [40/90], Loss: 0.0724\n",
      "Epoch [34/50], lter [60/90], Loss: 0.1874\n",
      "Epoch [34/50], lter [80/90], Loss: 0.0226\n",
      "Epoch [35/50], lter [20/90], Loss: 0.0649\n",
      "Epoch [35/50], lter [40/90], Loss: 0.0995\n",
      "Epoch [35/50], lter [60/90], Loss: 0.0011\n",
      "Epoch [35/50], lter [80/90], Loss: 0.0750\n",
      "Epoch [36/50], lter [20/90], Loss: 0.0057\n",
      "Epoch [36/50], lter [40/90], Loss: 0.0436\n",
      "Epoch [36/50], lter [60/90], Loss: 0.1532\n",
      "Epoch [36/50], lter [80/90], Loss: 0.0089\n",
      "Epoch [37/50], lter [20/90], Loss: 0.0410\n",
      "Epoch [37/50], lter [40/90], Loss: 0.2237\n",
      "Epoch [37/50], lter [60/90], Loss: 0.0665\n",
      "Epoch [37/50], lter [80/90], Loss: 0.0647\n",
      "Epoch [38/50], lter [20/90], Loss: 0.0021\n",
      "Epoch [38/50], lter [40/90], Loss: 0.0146\n",
      "Epoch [38/50], lter [60/90], Loss: 0.0110\n",
      "Epoch [38/50], lter [80/90], Loss: 0.0060\n",
      "Epoch [39/50], lter [20/90], Loss: 0.1571\n",
      "Epoch [39/50], lter [40/90], Loss: 0.0611\n",
      "Epoch [39/50], lter [60/90], Loss: 0.0053\n",
      "Epoch [39/50], lter [80/90], Loss: 0.2249\n",
      "Epoch [40/50], lter [20/90], Loss: 0.0029\n",
      "Epoch [40/50], lter [40/90], Loss: 0.0017\n",
      "Epoch [40/50], lter [60/90], Loss: 0.0047\n",
      "Epoch [40/50], lter [80/90], Loss: 0.0063\n",
      "Epoch [41/50], lter [20/90], Loss: 0.2036\n",
      "Epoch [41/50], lter [40/90], Loss: 0.0061\n",
      "Epoch [41/50], lter [60/90], Loss: 0.0183\n",
      "Epoch [41/50], lter [80/90], Loss: 0.0012\n",
      "Epoch [42/50], lter [20/90], Loss: 0.1074\n",
      "Epoch [42/50], lter [40/90], Loss: 0.0030\n",
      "Epoch [42/50], lter [60/90], Loss: 0.0007\n",
      "Epoch [42/50], lter [80/90], Loss: 0.1723\n",
      "Epoch [43/50], lter [20/90], Loss: 0.0024\n",
      "Epoch [43/50], lter [40/90], Loss: 0.0617\n",
      "Epoch [43/50], lter [60/90], Loss: 0.0043\n",
      "Epoch [43/50], lter [80/90], Loss: 0.0006\n",
      "Epoch [44/50], lter [20/90], Loss: 0.0158\n",
      "Epoch [44/50], lter [40/90], Loss: 0.0605\n",
      "Epoch [44/50], lter [60/90], Loss: 0.0018\n",
      "Epoch [44/50], lter [80/90], Loss: 0.0215\n",
      "Epoch [45/50], lter [20/90], Loss: 0.0273\n",
      "Epoch [45/50], lter [40/90], Loss: 0.0081\n",
      "Epoch [45/50], lter [60/90], Loss: 0.5069\n",
      "Epoch [45/50], lter [80/90], Loss: 0.0091\n",
      "Epoch [46/50], lter [20/90], Loss: 0.0536\n",
      "Epoch [46/50], lter [40/90], Loss: 0.1132\n",
      "Epoch [46/50], lter [60/90], Loss: 0.0019\n",
      "Epoch [46/50], lter [80/90], Loss: 0.0068\n",
      "Epoch [47/50], lter [20/90], Loss: 0.0044\n",
      "Epoch [47/50], lter [40/90], Loss: 0.0045\n",
      "Epoch [47/50], lter [60/90], Loss: 0.1696\n",
      "Epoch [47/50], lter [80/90], Loss: 0.0943\n",
      "Epoch [48/50], lter [20/90], Loss: 0.0024\n",
      "Epoch [48/50], lter [40/90], Loss: 0.0026\n",
      "Epoch [48/50], lter [60/90], Loss: 0.0955\n",
      "Epoch [48/50], lter [80/90], Loss: 0.0046\n",
      "Epoch [49/50], lter [20/90], Loss: 0.0032\n",
      "Epoch [49/50], lter [40/90], Loss: 0.0002\n",
      "Epoch [49/50], lter [60/90], Loss: 0.0022\n",
      "Epoch [49/50], lter [80/90], Loss: 0.0006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], lter [20/90], Loss: 0.0042\n",
      "Epoch [50/50], lter [40/90], Loss: 0.1019\n",
      "Epoch [50/50], lter [60/90], Loss: 0.0025\n",
      "Epoch [50/50], lter [80/90], Loss: 0.0009\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    total_batch = len(train_data) // batch_size\n",
    "    \n",
    "    for i, (batch_text, batch_labels) in enumerate(train_loader):\n",
    "        \n",
    "        X = batch_text.view(-1, dim)\n",
    "        Y = batch_labels\n",
    "        \n",
    "        pre = model(X)\n",
    "        cost = loss(pre, Y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 20 == 0:\n",
    "            print('Epoch [%d/%d], lter [%d/%d], Loss: %.4f'\n",
    "                 %(epoch+1, num_epochs, i+1, total_batch, cost.item()))\n",
    "    \n",
    "print(\"Learning Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.7 Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.from_numpy(test_data).type(torch.FloatTensor)\n",
    "y_test = torch.from_numpy(test_label).type(torch.LongTensor)\n",
    "\n",
    "test_data = TensorDataset(x_test, y_test)\n",
    "\n",
    "test_loader  = DataLoader(dataset=test_data,\n",
    "                          batch_size=1,\n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test text: 78.547855 %\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for text, labels in test_loader:\n",
    "    \n",
    "    text = text.view(-1, dim)\n",
    "    outputs = model(text)\n",
    "    \n",
    "    _, pre = torch.max(outputs.data, 1)\n",
    "    total += 1\n",
    "    correct += (pre == labels).sum()\n",
    "    \n",
    "print('Accuracy of test text: %f %%' % (100 * float(correct) / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.8 Test Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IsitHot(string) :\n",
    "    \n",
    "    results= []\n",
    "    tokens = tokenizer.pos(string, norm=True, stem=True)\n",
    "\n",
    "    for token in tokens:\n",
    "        if not token[1] in [\"Josa\", \"Eomi\", \"Punctuation\"]:\n",
    "            results.append(token[0])\n",
    "   \n",
    "    sample = cnv.transform([\" \".join(results).strip()]).toarray()\n",
    "    sample = torch.from_numpy(sample).type(torch.FloatTensor)\n",
    "    outputs = model(sample)\n",
    "    pre = torch.max(outputs.data, 1)[1].numpy()\n",
    "    \n",
    "    if pre == 0 : \n",
    "        print(\"분석 결과 : 발열 거의 없음\")\n",
    "    elif pre == 1 :\n",
    "        print(\"분석 결과 : 발열 조금 있음\")\n",
    "    else :\n",
    "        print(\"분석 결과 : 발열 매우 심함\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분석 결과 : 발열 매우 심함\n"
     ]
    }
   ],
   "source": [
    "IsitHot(\"노트북이 너무 뜨거워요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분석 결과 : 발열 거의 없음\n"
     ]
    }
   ],
   "source": [
    "IsitHot(\"발열을 잘 잡았네요\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p36]",
   "language": "python",
   "name": "conda-env-pytorch_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
