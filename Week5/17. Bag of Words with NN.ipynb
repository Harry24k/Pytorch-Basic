{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17. Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import pandas as pd\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.1 Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# G마켓에 좋은 평만 있어서 사봤는데.. 정말 진짜 진짜 사지마세요. 개. 쓰. 레. 기 (진심) 입니다. 액정부터 짜증나는 TN패널에, 하드 SSD인걸로 알았는데, 속도는 저질 SD카드 꽂아 놓은것 같습니다. 정말 느려터집니다. 저는 단지 인터넷 뱅킹만 할려고, 샀단 말입니다. 그런데 인터넷 뱅킹 프로그램까는데만 10~20분 걸립니다. 뭐약!! 이게!! 분노로 인해 볼때마다 짜증납니다. 밤에 잠도 안오고요.. 사시면 분명 후회하실겁니다. 아! 진짜 G마켓 프리미엄평으로 실날하게 사진찍어서 올리려고했는데, 먹고 산다고 바빠서 프리미엄 평 못 올린게 정말 천추의 한이네요!!\\n# 원래 그런 줄 알고 사는 \"저가 제품\"이라고 생각합니다만. IPS라는 언급이 없으니 당연히 TN 패널일 테고, EMMC는 SSD가 아니고 SD 카드 내장된 것 같은 것이라 원래 SSD보다 느린 것이고, CPU도 아톰이니 뭐 당연히 느리죠. 그런 것 다 감안하고 \"싸고 가볍다\"는 조건으로 사는 제품인데요. 뭐 '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = codecs.open(\"data/reviews.txt\", 'r', 'utf-8')\n",
    "f.read()[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.2 Extract Setences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"발열\", \"소음\"]\n",
    "\n",
    "for keyword in keywords :\n",
    "    temp_list = []\n",
    "    save_name = \"data/reviews_\" + keyword + \".txt\"\n",
    "    f = codecs.open(\"data/reviews.txt\", 'r', 'utf-8')\n",
    "    t = codecs.open(save_name, 'w', 'utf-8')\n",
    "    \n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line: break\n",
    "        if keyword in line :\n",
    "            temp_list.append(line)\n",
    "            \n",
    "    set_list = list(set(temp_list))\n",
    "    \n",
    "    for item in set_list :\n",
    "        t.write(item)\n",
    "        \n",
    "    f.close()\n",
    "    t.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# 이게 게이밍 노트북이라뇨?? 1050 달고 게이밍이라고 하다니.. 고사양게임들은 사양 타협을 해야되겠네요. 라이트한 게임유저면 1050ti 정도면 상관없지만 게이밍이라고 말할려면 최소 1060은 가셔야됩니다. 그리고 이제품 발열 자체가 상당하던데 게이밍으론 부적절한 제품입니다. 예를 들어 cpu가 100도를 견딘다고 하면 매일 90도 이상 계속 돌아가면 문제가 생기는건 당연하죠. 그로인해 노트북 회사들은 발열제어에 힘쓰는거구요. 뒷판 파공을 해놨지만 저거 전혀 쓸모 없습니다. 애초에 저런식으로 파공을 해야됬나 싶을정도.. 삼성 이번꺼 정말 실망스러운 제품입니다. 대기업이라 as는 믿고 맡기겠지만 그거 외에는 장점이 없는 제품이네요..\\n# 삼성이라는 브랜드에 외산 노트북과 엇비슷한 가격이라는 점은 매우 강점인 것 같습니다. 아무래도 노트북은 데스크탑과는 다르게 자가 수리(부품교환)이 어렵다보니 as센터를 이용해야하는데, 삼성의 as는 타사의 추종을 불허하잖아요? 성능은 중간급 정도'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = codecs.open(\"data/reviews_발열.txt\", 'r', 'utf-8')\n",
    "f.read()[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.3 Load Scored Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data/score_발열.xlsx\"\n",
    "sheet_name = \"Sheet1\"\n",
    "data = pd.read_excel(filename, sheet_name = sheet_name, header = 0)\n",
    "\n",
    "csv_data = [item.replace(\"#\", \"\").strip() for item in data['Review']]\n",
    "csv_label = data['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['발열히 심한거 같은데 여름이라 그런가?..',\n",
       " '발열이좀 심한거 같아서 걱정이에요',\n",
       " '발열이심하더라구요',\n",
       " '발열이너무심한게 제일큰 단점인것 같고 그외에 불편한점은',\n",
       " '발열이...정말...심합니다']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = [sum(csv_label == 0), sum(csv_label == 1), sum(csv_label == 2)]\n",
    "plt.bar(range(len(scores)),scores, color=\"#ff5733\")\n",
    "\n",
    "plt.title(\"Average Laptop's Score of Heat\")\n",
    "plt.xlabel(\"Heat Score\")\n",
    "plt.ylabel(\"Reviews\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.4 Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Okt()\n",
    "doc = []\n",
    "\n",
    "for sentence in csv_data :\n",
    "    results= []\n",
    "    tokens = tokenizer.pos(sentence, norm=True, stem=True)\n",
    "        \n",
    "    for token in tokens:\n",
    "        if not token[1] in [\"Josa\", \"Eomi\", \"Punctuation\"]:\n",
    "            results.append(token[0])\n",
    "    doc.append(\" \".join(results).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['발열 히 심하다 같다 여름 그 런가',\n",
       " '발열 이 좀 심하다 같다 걱정',\n",
       " '발열 심하다',\n",
       " '발열 이 너 무심하다 제일 크다 단점 것 같다 그 외 불편하다 점',\n",
       " '발열 정말 심하다']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer\n",
    "cnv = CountVectorizer(ngram_range=(1,1), min_df = 3)\n",
    "\n",
    "data = cnv.fit_transform(doc).toarray()\n",
    "label = csv_label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorizer\n",
    "# tfidv = TfidfVectorizer().fit(data)\n",
    "# data = tfidv.transform(data).toarray()\n",
    "\n",
    "# data = pd.DataFrame(data)\n",
    "# data = (data - data.mean()) / (data.max() - data.min() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'발열': 112,\n",
       " '심하다': 156,\n",
       " '같다': 13,\n",
       " '여름': 187,\n",
       " '걱정': 16,\n",
       " '무심하다': 104,\n",
       " '크다': 266,\n",
       " '단점': 57,\n",
       " '불편하다': 125,\n",
       " '정말': 237,\n",
       " '확실하다': 292,\n",
       " '심해': 157,\n",
       " '노트북': 45,\n",
       " '쿨러': 263,\n",
       " '사용': 134,\n",
       " '크게': 265,\n",
       " '진짜': 250,\n",
       " '너무': 43,\n",
       " '많이': 93,\n",
       " '있다': 218,\n",
       " '장시간': 228,\n",
       " '높다': 47,\n",
       " '프로그램': 275,\n",
       " '한편': 283,\n",
       " '이다': 204,\n",
       " '심다': 155,\n",
       " '밧데리': 113,\n",
       " 'cpu': 4,\n",
       " '용량': 200,\n",
       " '빼다': 131,\n",
       " '괜찮다': 22,\n",
       " '느낌': 50,\n",
       " '하지만': 281,\n",
       " '자판': 221,\n",
       " '조금': 241,\n",
       " '속도': 149,\n",
       " '매우': 94,\n",
       " '좋다': 244,\n",
       " '이전': 211,\n",
       " '하다': 279,\n",
       " '뜨겁다': 83,\n",
       " '가볍다': 10,\n",
       " '조용하다': 242,\n",
       " '마음': 88,\n",
       " '듭니': 72,\n",
       " '돌아가다': 65,\n",
       " '불량': 124,\n",
       " '심해지다': 158,\n",
       " '생기다': 141,\n",
       " '소리': 147,\n",
       " '나다': 38,\n",
       " '그렇다': 31,\n",
       " '부분': 122,\n",
       " '문제': 107,\n",
       " '끊기다': 37,\n",
       " '쓰다': 160,\n",
       " '약간': 175,\n",
       " '게임': 18,\n",
       " '돌리다': 64,\n",
       " '정도': 236,\n",
       " '성능': 145,\n",
       " '라면': 85,\n",
       " '지다': 249,\n",
       " '이렇다': 206,\n",
       " '부팅': 123,\n",
       " '화상': 289,\n",
       " '원래': 202,\n",
       " '모르다': 100,\n",
       " '않다': 171,\n",
       " '구매': 24,\n",
       " '신분': 154,\n",
       " '야하다': 174,\n",
       " '제외': 239,\n",
       " '자주': 220,\n",
       " '발생': 111,\n",
       " '삼성': 137,\n",
       " '소음': 148,\n",
       " '치다': 259,\n",
       " '만족하다': 91,\n",
       " '배터리': 116,\n",
       " '빠르다': 128,\n",
       " '무엇': 105,\n",
       " '생각': 140,\n",
       " '하드': 280,\n",
       " '보드': 119,\n",
       " '왼쪽': 199,\n",
       " '상당하다': 138,\n",
       " '살짝': 136,\n",
       " '메탈': 95,\n",
       " '비다': 126,\n",
       " '비추다': 127,\n",
       " '휴대': 294,\n",
       " '다니다': 54,\n",
       " '많다': 92,\n",
       " '느리다': 51,\n",
       " '다른': 55,\n",
       " '제품': 240,\n",
       " '시간': 152,\n",
       " '센터': 146,\n",
       " '늘다': 52,\n",
       " '이제': 213,\n",
       " '조절': 243,\n",
       " '약하다': 176,\n",
       " '어쩔': 182,\n",
       " '전혀': 233,\n",
       " '잡지': 226,\n",
       " '해보다': 284,\n",
       " '편이': 271,\n",
       " '되다': 67,\n",
       " '화이트': 290,\n",
       " '다소': 56,\n",
       " '느껴지다': 48,\n",
       " '하나': 277,\n",
       " '따르다': 77,\n",
       " '내다': 42,\n",
       " '사양': 133,\n",
       " '낮다': 41,\n",
       " '양호': 178,\n",
       " '상태': 139,\n",
       " '차이': 253,\n",
       " '보다': 118,\n",
       " '수가': 150,\n",
       " '없다': 185,\n",
       " '인하다': 215,\n",
       " '지금': 248,\n",
       " '어떻다': 181,\n",
       " '또한': 81,\n",
       " '가격': 8,\n",
       " '때문': 79,\n",
       " '켜다': 262,\n",
       " '충전': 258,\n",
       " '능력': 53,\n",
       " '떨어지다': 80,\n",
       " '오래되다': 194,\n",
       " '자다': 219,\n",
       " '관리': 21,\n",
       " '돼다': 66,\n",
       " '걸리다': 17,\n",
       " '아니다': 163,\n",
       " '안되다': 169,\n",
       " '그냥': 26,\n",
       " '받침': 110,\n",
       " '절대': 234,\n",
       " '보이다': 120,\n",
       " '고민': 20,\n",
       " '빠지다': 130,\n",
       " '모두': 98,\n",
       " '한성': 282,\n",
       " '구성': 25,\n",
       " 'as': 3,\n",
       " '굉장하다': 23,\n",
       " '깔끔하다': 36,\n",
       " '이쁘다': 208,\n",
       " '모델': 97,\n",
       " '현상': 286,\n",
       " '50': 1,\n",
       " '준수': 246,\n",
       " '처리': 254,\n",
       " '잡다': 225,\n",
       " '얇다': 177,\n",
       " '오래': 193,\n",
       " '쓸다': 162,\n",
       " '일이': 217,\n",
       " '인터넷': 214,\n",
       " '100': 0,\n",
       " '그래픽': 28,\n",
       " '장점': 229,\n",
       " '훨씬': 293,\n",
       " '해소': 285,\n",
       " '패드': 269,\n",
       " '일어나서': 216,\n",
       " '쿨링': 264,\n",
       " '이상': 209,\n",
       " '기본': 35,\n",
       " '서비스': 142,\n",
       " '들다': 71,\n",
       " '사은': 135,\n",
       " '주다': 245,\n",
       " '어느': 180,\n",
       " '문서': 106,\n",
       " '작업': 223,\n",
       " '편입': 272,\n",
       " '아주': 166,\n",
       " '컴퓨터': 261,\n",
       " '배송': 115,\n",
       " '이정': 212,\n",
       " '무게': 102,\n",
       " '그램': 29,\n",
       " '두다': 69,\n",
       " '온도': 195,\n",
       " '아쉽다': 164,\n",
       " '그래도': 27,\n",
       " '예쁘다': 191,\n",
       " '따다': 75,\n",
       " '안나': 168,\n",
       " '디자인': 74,\n",
       " '가다': 9,\n",
       " '편하다': 273,\n",
       " '겨울': 19,\n",
       " '이면': 207,\n",
       " '나쁘다': 39,\n",
       " '필요': 276,\n",
       " '받다': 109,\n",
       " '액정': 173,\n",
       " '돌다': 63,\n",
       " '아예': 165,\n",
       " '레노버': 86,\n",
       " '처음': 255,\n",
       " '써다': 159,\n",
       " '얘기': 179,\n",
       " '느끼다': 49,\n",
       " '나오다': 40,\n",
       " '등등': 73,\n",
       " '데스크탑': 62,\n",
       " '연결': 189,\n",
       " '아직': 167,\n",
       " '수준': 151,\n",
       " '뜨다': 84,\n",
       " '사다': 132,\n",
       " '설치': 144,\n",
       " '평소': 274,\n",
       " '70': 2,\n",
       " '신경': 153,\n",
       " '쓰이다': 161,\n",
       " '노트': 44,\n",
       " '따뜻하다': 76,\n",
       " '최고': 256,\n",
       " 'ssd': 6,\n",
       " '카드': 260,\n",
       " '마감': 87,\n",
       " '없이': 186,\n",
       " '윈도우': 203,\n",
       " '보통': 121,\n",
       " '펴다': 270,\n",
       " '감다': 12,\n",
       " '별로': 117,\n",
       " '화면': 288,\n",
       " 'ㅜㅜ': 7,\n",
       " '엄청': 183,\n",
       " '개선': 14,\n",
       " '차다': 252,\n",
       " '완벽하다': 196,\n",
       " '열량': 190,\n",
       " '빠릿빠릿': 129,\n",
       " '그렇게': 30,\n",
       " '기능': 33,\n",
       " '오다': 192,\n",
       " '모니터': 96,\n",
       " '적당하다': 232,\n",
       " '던지다': 61,\n",
       " '거의': 15,\n",
       " '무겁다': 101,\n",
       " '추천': 257,\n",
       " '만족': 89,\n",
       " '그리다': 32,\n",
       " '대다': 58,\n",
       " '대비': 60,\n",
       " '딱하다': 78,\n",
       " '뒤틀리다': 70,\n",
       " '짧다': 251,\n",
       " '모든': 99,\n",
       " '제어': 238,\n",
       " '완전': 197,\n",
       " '기다': 34,\n",
       " '알다': 172,\n",
       " '가성': 11,\n",
       " '잡히다': 227,\n",
       " '우수하다': 201,\n",
       " '증상': 247,\n",
       " '뛰어나다': 82,\n",
       " '되어다': 68,\n",
       " '적다': 231,\n",
       " '선택': 143,\n",
       " '만족스럽다': 90,\n",
       " '현재': 287,\n",
       " '화질': 291,\n",
       " '특히': 267,\n",
       " '하니': 278,\n",
       " '이렇게': 205,\n",
       " '놀라다': 46,\n",
       " '점수': 235,\n",
       " '물론': 108,\n",
       " '무리': 103,\n",
       " '외관': 198,\n",
       " '대단하다': 59,\n",
       " '역시': 188,\n",
       " '작다': 222,\n",
       " '저렴하다': 230,\n",
       " '잡고': 224,\n",
       " '엄청나다': 184,\n",
       " 'ips': 5,\n",
       " '패널': 268,\n",
       " '안심': 170,\n",
       " '배그': 114,\n",
       " '이슈': 210}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnv.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.5 Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = len(cnv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "908\n",
      "303\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data, train_label, test_label = train_test_split(data, label, stratify = label)\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(train_data).type(torch.FloatTensor)\n",
    "y = torch.from_numpy(train_label).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([908]), torch.Size([908, 295]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size() , x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Data.TensorDataset(x, y)\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "train_loader  = Data.DataLoader(dataset=train_data,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=1,\n",
    "                                          drop_last = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.6 Define and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1 = nn.Linear(dim, 200, bias = True)\n",
    "linear2 = nn.Linear(200, 3, bias = True)\n",
    "relu = nn.ReLU()\n",
    "\n",
    "model = nn.Sequential(linear1, relu, linear2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], lter [20/90], Loss: 0.9519\n",
      "Epoch [1/50], lter [40/90], Loss: 1.0120\n",
      "Epoch [1/50], lter [60/90], Loss: 0.6827\n",
      "Epoch [1/50], lter [80/90], Loss: 0.8269\n",
      "Epoch [2/50], lter [20/90], Loss: 0.2934\n",
      "Epoch [2/50], lter [40/90], Loss: 0.4353\n",
      "Epoch [2/50], lter [60/90], Loss: 0.3538\n",
      "Epoch [2/50], lter [80/90], Loss: 0.5173\n",
      "Epoch [3/50], lter [20/90], Loss: 0.6698\n",
      "Epoch [3/50], lter [40/90], Loss: 0.5007\n",
      "Epoch [3/50], lter [60/90], Loss: 0.2530\n",
      "Epoch [3/50], lter [80/90], Loss: 0.6136\n",
      "Epoch [4/50], lter [20/90], Loss: 0.2339\n",
      "Epoch [4/50], lter [40/90], Loss: 0.2854\n",
      "Epoch [4/50], lter [60/90], Loss: 0.1022\n",
      "Epoch [4/50], lter [80/90], Loss: 0.1698\n",
      "Epoch [5/50], lter [20/90], Loss: 0.1024\n",
      "Epoch [5/50], lter [40/90], Loss: 0.4401\n",
      "Epoch [5/50], lter [60/90], Loss: 0.1557\n",
      "Epoch [5/50], lter [80/90], Loss: 0.0826\n",
      "Epoch [6/50], lter [20/90], Loss: 0.2376\n",
      "Epoch [6/50], lter [40/90], Loss: 0.2841\n",
      "Epoch [6/50], lter [60/90], Loss: 0.2698\n",
      "Epoch [6/50], lter [80/90], Loss: 0.1092\n",
      "Epoch [7/50], lter [20/90], Loss: 0.1274\n",
      "Epoch [7/50], lter [40/90], Loss: 0.2107\n",
      "Epoch [7/50], lter [60/90], Loss: 0.0298\n",
      "Epoch [7/50], lter [80/90], Loss: 0.3612\n",
      "Epoch [8/50], lter [20/90], Loss: 0.1420\n",
      "Epoch [8/50], lter [40/90], Loss: 0.1657\n",
      "Epoch [8/50], lter [60/90], Loss: 0.2588\n",
      "Epoch [8/50], lter [80/90], Loss: 0.1293\n",
      "Epoch [9/50], lter [20/90], Loss: 0.1708\n",
      "Epoch [9/50], lter [40/90], Loss: 0.1380\n",
      "Epoch [9/50], lter [60/90], Loss: 0.2813\n",
      "Epoch [9/50], lter [80/90], Loss: 0.2359\n",
      "Epoch [10/50], lter [20/90], Loss: 0.0732\n",
      "Epoch [10/50], lter [40/90], Loss: 0.2134\n",
      "Epoch [10/50], lter [60/90], Loss: 0.1066\n",
      "Epoch [10/50], lter [80/90], Loss: 0.1176\n",
      "Epoch [11/50], lter [20/90], Loss: 0.2295\n",
      "Epoch [11/50], lter [40/90], Loss: 0.1072\n",
      "Epoch [11/50], lter [60/90], Loss: 0.0611\n",
      "Epoch [11/50], lter [80/90], Loss: 0.2982\n",
      "Epoch [12/50], lter [20/90], Loss: 0.0890\n",
      "Epoch [12/50], lter [40/90], Loss: 0.0659\n",
      "Epoch [12/50], lter [60/90], Loss: 0.0530\n",
      "Epoch [12/50], lter [80/90], Loss: 0.0324\n",
      "Epoch [13/50], lter [20/90], Loss: 0.0307\n",
      "Epoch [13/50], lter [40/90], Loss: 0.3328\n",
      "Epoch [13/50], lter [60/90], Loss: 0.1667\n",
      "Epoch [13/50], lter [80/90], Loss: 0.1303\n",
      "Epoch [14/50], lter [20/90], Loss: 0.0255\n",
      "Epoch [14/50], lter [40/90], Loss: 0.0472\n",
      "Epoch [14/50], lter [60/90], Loss: 0.0348\n",
      "Epoch [14/50], lter [80/90], Loss: 0.2213\n",
      "Epoch [15/50], lter [20/90], Loss: 0.0795\n",
      "Epoch [15/50], lter [40/90], Loss: 0.1576\n",
      "Epoch [15/50], lter [60/90], Loss: 0.0828\n",
      "Epoch [15/50], lter [80/90], Loss: 0.1394\n",
      "Epoch [16/50], lter [20/90], Loss: 0.0395\n",
      "Epoch [16/50], lter [40/90], Loss: 0.1563\n",
      "Epoch [16/50], lter [60/90], Loss: 0.0080\n",
      "Epoch [16/50], lter [80/90], Loss: 0.2049\n",
      "Epoch [17/50], lter [20/90], Loss: 0.0692\n",
      "Epoch [17/50], lter [40/90], Loss: 0.0188\n",
      "Epoch [17/50], lter [60/90], Loss: 0.0472\n",
      "Epoch [17/50], lter [80/90], Loss: 0.0060\n",
      "Epoch [18/50], lter [20/90], Loss: 0.1386\n",
      "Epoch [18/50], lter [40/90], Loss: 0.1572\n",
      "Epoch [18/50], lter [60/90], Loss: 0.0022\n",
      "Epoch [18/50], lter [80/90], Loss: 0.0781\n",
      "Epoch [19/50], lter [20/90], Loss: 0.1483\n",
      "Epoch [19/50], lter [40/90], Loss: 0.0647\n",
      "Epoch [19/50], lter [60/90], Loss: 0.1402\n",
      "Epoch [19/50], lter [80/90], Loss: 0.0088\n",
      "Epoch [20/50], lter [20/90], Loss: 0.1759\n",
      "Epoch [20/50], lter [40/90], Loss: 0.0286\n",
      "Epoch [20/50], lter [60/90], Loss: 0.2834\n",
      "Epoch [20/50], lter [80/90], Loss: 0.0113\n",
      "Epoch [21/50], lter [20/90], Loss: 0.0302\n",
      "Epoch [21/50], lter [40/90], Loss: 0.0026\n",
      "Epoch [21/50], lter [60/90], Loss: 0.0085\n",
      "Epoch [21/50], lter [80/90], Loss: 0.0726\n",
      "Epoch [22/50], lter [20/90], Loss: 0.1185\n",
      "Epoch [22/50], lter [40/90], Loss: 0.2254\n",
      "Epoch [22/50], lter [60/90], Loss: 0.0399\n",
      "Epoch [22/50], lter [80/90], Loss: 0.2764\n",
      "Epoch [23/50], lter [20/90], Loss: 0.0443\n",
      "Epoch [23/50], lter [40/90], Loss: 0.1016\n",
      "Epoch [23/50], lter [60/90], Loss: 0.0367\n",
      "Epoch [23/50], lter [80/90], Loss: 0.0753\n",
      "Epoch [24/50], lter [20/90], Loss: 0.0340\n",
      "Epoch [24/50], lter [40/90], Loss: 0.0506\n",
      "Epoch [24/50], lter [60/90], Loss: 0.1398\n",
      "Epoch [24/50], lter [80/90], Loss: 0.0473\n",
      "Epoch [25/50], lter [20/90], Loss: 0.0046\n",
      "Epoch [25/50], lter [40/90], Loss: 0.1127\n",
      "Epoch [25/50], lter [60/90], Loss: 0.1720\n",
      "Epoch [25/50], lter [80/90], Loss: 0.0159\n",
      "Epoch [26/50], lter [20/90], Loss: 0.0674\n",
      "Epoch [26/50], lter [40/90], Loss: 0.0029\n",
      "Epoch [26/50], lter [60/90], Loss: 0.0188\n",
      "Epoch [26/50], lter [80/90], Loss: 0.0236\n",
      "Epoch [27/50], lter [20/90], Loss: 0.0078\n",
      "Epoch [27/50], lter [40/90], Loss: 0.1144\n",
      "Epoch [27/50], lter [60/90], Loss: 0.1222\n",
      "Epoch [27/50], lter [80/90], Loss: 0.2096\n",
      "Epoch [28/50], lter [20/90], Loss: 0.0528\n",
      "Epoch [28/50], lter [40/90], Loss: 0.0108\n",
      "Epoch [28/50], lter [60/90], Loss: 0.0540\n",
      "Epoch [28/50], lter [80/90], Loss: 0.0260\n",
      "Epoch [29/50], lter [20/90], Loss: 0.0763\n",
      "Epoch [29/50], lter [40/90], Loss: 0.0046\n",
      "Epoch [29/50], lter [60/90], Loss: 0.1203\n",
      "Epoch [29/50], lter [80/90], Loss: 0.1171\n",
      "Epoch [30/50], lter [20/90], Loss: 0.1575\n",
      "Epoch [30/50], lter [40/90], Loss: 0.0018\n",
      "Epoch [30/50], lter [60/90], Loss: 0.0177\n",
      "Epoch [30/50], lter [80/90], Loss: 0.0050\n",
      "Epoch [31/50], lter [20/90], Loss: 0.0407\n",
      "Epoch [31/50], lter [40/90], Loss: 0.1064\n",
      "Epoch [31/50], lter [60/90], Loss: 0.0878\n",
      "Epoch [31/50], lter [80/90], Loss: 0.0242\n",
      "Epoch [32/50], lter [20/90], Loss: 0.1509\n",
      "Epoch [32/50], lter [40/90], Loss: 0.0272\n",
      "Epoch [32/50], lter [60/90], Loss: 0.0050\n",
      "Epoch [32/50], lter [80/90], Loss: 0.0214\n",
      "Epoch [33/50], lter [20/90], Loss: 0.1043\n",
      "Epoch [33/50], lter [40/90], Loss: 0.0068\n",
      "Epoch [33/50], lter [60/90], Loss: 0.0096\n",
      "Epoch [33/50], lter [80/90], Loss: 0.0848\n",
      "Epoch [34/50], lter [20/90], Loss: 0.2031\n",
      "Epoch [34/50], lter [40/90], Loss: 0.0196\n",
      "Epoch [34/50], lter [60/90], Loss: 0.1432\n",
      "Epoch [34/50], lter [80/90], Loss: 0.0107\n",
      "Epoch [35/50], lter [20/90], Loss: 0.0402\n",
      "Epoch [35/50], lter [40/90], Loss: 0.0031\n",
      "Epoch [35/50], lter [60/90], Loss: 0.0985\n",
      "Epoch [35/50], lter [80/90], Loss: 0.0058\n",
      "Epoch [36/50], lter [20/90], Loss: 0.1011\n",
      "Epoch [36/50], lter [40/90], Loss: 0.0095\n",
      "Epoch [36/50], lter [60/90], Loss: 0.0002\n",
      "Epoch [36/50], lter [80/90], Loss: 0.0108\n",
      "Epoch [37/50], lter [20/90], Loss: 0.0976\n",
      "Epoch [37/50], lter [40/90], Loss: 0.1624\n",
      "Epoch [37/50], lter [60/90], Loss: 0.1174\n",
      "Epoch [37/50], lter [80/90], Loss: 0.0038\n",
      "Epoch [38/50], lter [20/90], Loss: 0.0456\n",
      "Epoch [38/50], lter [40/90], Loss: 0.0304\n",
      "Epoch [38/50], lter [60/90], Loss: 0.1697\n",
      "Epoch [38/50], lter [80/90], Loss: 0.1120\n",
      "Epoch [39/50], lter [20/90], Loss: 0.0416\n",
      "Epoch [39/50], lter [40/90], Loss: 0.1402\n",
      "Epoch [39/50], lter [60/90], Loss: 0.0685\n",
      "Epoch [39/50], lter [80/90], Loss: 0.2940\n",
      "Epoch [40/50], lter [20/90], Loss: 0.0111\n",
      "Epoch [40/50], lter [40/90], Loss: 0.0055\n",
      "Epoch [40/50], lter [60/90], Loss: 0.1022\n",
      "Epoch [40/50], lter [80/90], Loss: 0.0801\n",
      "Epoch [41/50], lter [20/90], Loss: 0.2253\n",
      "Epoch [41/50], lter [40/90], Loss: 0.0070\n",
      "Epoch [41/50], lter [60/90], Loss: 0.0993\n",
      "Epoch [41/50], lter [80/90], Loss: 0.0026\n",
      "Epoch [42/50], lter [20/90], Loss: 0.1464\n",
      "Epoch [42/50], lter [40/90], Loss: 0.0695\n",
      "Epoch [42/50], lter [60/90], Loss: 0.0071\n",
      "Epoch [42/50], lter [80/90], Loss: 0.0419\n",
      "Epoch [43/50], lter [20/90], Loss: 0.3400\n",
      "Epoch [43/50], lter [40/90], Loss: 0.0082\n",
      "Epoch [43/50], lter [60/90], Loss: 0.0012\n",
      "Epoch [43/50], lter [80/90], Loss: 0.0046\n",
      "Epoch [44/50], lter [20/90], Loss: 0.0039\n",
      "Epoch [44/50], lter [40/90], Loss: 0.1091\n",
      "Epoch [44/50], lter [60/90], Loss: 0.0646\n",
      "Epoch [44/50], lter [80/90], Loss: 0.0014\n",
      "Epoch [45/50], lter [20/90], Loss: 0.0507\n",
      "Epoch [45/50], lter [40/90], Loss: 0.0381\n",
      "Epoch [45/50], lter [60/90], Loss: 0.0010\n",
      "Epoch [45/50], lter [80/90], Loss: 0.0275\n",
      "Epoch [46/50], lter [20/90], Loss: 0.0008\n",
      "Epoch [46/50], lter [40/90], Loss: 0.0888\n",
      "Epoch [46/50], lter [60/90], Loss: 0.0020\n",
      "Epoch [46/50], lter [80/90], Loss: 0.0015\n",
      "Epoch [47/50], lter [20/90], Loss: 0.0003\n",
      "Epoch [47/50], lter [40/90], Loss: 0.0110\n",
      "Epoch [47/50], lter [60/90], Loss: 0.0220\n",
      "Epoch [47/50], lter [80/90], Loss: 0.0023\n",
      "Epoch [48/50], lter [20/90], Loss: 0.1264\n",
      "Epoch [48/50], lter [40/90], Loss: 0.0191\n",
      "Epoch [48/50], lter [60/90], Loss: 0.0028\n",
      "Epoch [48/50], lter [80/90], Loss: 0.0025\n",
      "Epoch [49/50], lter [20/90], Loss: 0.0002\n",
      "Epoch [49/50], lter [40/90], Loss: 0.0004\n",
      "Epoch [49/50], lter [60/90], Loss: 0.0002\n",
      "Epoch [49/50], lter [80/90], Loss: 0.0099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], lter [20/90], Loss: 0.0036\n",
      "Epoch [50/50], lter [40/90], Loss: 0.1335\n",
      "Epoch [50/50], lter [60/90], Loss: 0.0521\n",
      "Epoch [50/50], lter [80/90], Loss: 0.0004\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    total_batch = len(train_data) // batch_size\n",
    "    \n",
    "    for i, (batch_text, batch_labels) in enumerate(train_loader):\n",
    "        \n",
    "        X = batch_text.view(-1, dim)\n",
    "        Y = batch_labels\n",
    "        \n",
    "        pre = model(X)\n",
    "        cost = loss(pre, Y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 20 == 0:\n",
    "            print('Epoch [%d/%d], lter [%d/%d], Loss: %.4f'\n",
    "                 %(epoch+1, num_epochs, i+1, total_batch, cost.item()))\n",
    "    \n",
    "print(\"Learning Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.7 Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.from_numpy(test_data).type(torch.FloatTensor)\n",
    "y_test = torch.from_numpy(test_label).type(torch.LongTensor)\n",
    "\n",
    "test_data = Data.TensorDataset(x_test, y_test)\n",
    "\n",
    "test_loader  = Data.DataLoader(dataset=test_data,\n",
    "                                          batch_size=1,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test text: 78.877888 %\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for text, labels in test_loader:\n",
    "    \n",
    "    text = text.view(-1, dim)\n",
    "    outputs = model(text)\n",
    "    \n",
    "    _, pre = torch.max(outputs.data, 1)\n",
    "    total += 1\n",
    "    correct += (pre == labels).sum()\n",
    "    \n",
    "print('Accuracy of test text: %f %%' % (100 * float(correct) / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.8 Test Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IsitHot(string) :\n",
    "    \n",
    "    results= []\n",
    "    tokens = tokenizer.pos(string, norm=True, stem=True)\n",
    "\n",
    "    for token in tokens:\n",
    "        if not token[1] in [\"Josa\", \"Eomi\", \"Punctuation\"]:\n",
    "            results.append(token[0])\n",
    "   \n",
    "    sample = cnv.transform([\" \".join(results).strip()]).toarray()\n",
    "    sample = torch.from_numpy(sample).type(torch.FloatTensor)\n",
    "    outputs = model(sample)\n",
    "    pre = torch.max(outputs.data, 1)[1].numpy()\n",
    "    \n",
    "    if pre == 0 : \n",
    "        print(\"분석 결과 : 발열 거의 없음\")\n",
    "    elif pre == 1 :\n",
    "        print(\"분석 결과 : 발열 조금 있음\")\n",
    "    else :\n",
    "        print(\"분석 결과 : 발열 매우 심함\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분석 결과 : 발열 매우 심함\n"
     ]
    }
   ],
   "source": [
    "IsitHot(\"노트북이 너무 뜨거워요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분석 결과 : 발열 거의 없음\n"
     ]
    }
   ],
   "source": [
    "IsitHot(\"발열을 잘 잡았네요\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
