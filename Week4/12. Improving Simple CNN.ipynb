{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Improving Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.utils\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.1 Preparing Custom Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ㄱ', 'ㄲ', 'ㄴ', 'ㄷ', 'ㄸ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅃ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ', 'ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', 'ㅕ', 'ㅖ', 'ㅗ', 'ㅘ', 'ㅙ', 'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', 'ㅡ', 'ㅢ', 'ㅣ']\n",
      "{'ㄱ': 0, 'ㄲ': 1, 'ㄴ': 2, 'ㄷ': 3, 'ㄸ': 4, 'ㄹ': 5, 'ㅁ': 6, 'ㅂ': 7, 'ㅃ': 8, 'ㅅ': 9, 'ㅆ': 10, 'ㅇ': 11, 'ㅈ': 12, 'ㅉ': 13, 'ㅊ': 14, 'ㅋ': 15, 'ㅌ': 16, 'ㅍ': 17, 'ㅎ': 18, 'ㅏ': 19, 'ㅐ': 20, 'ㅑ': 21, 'ㅒ': 22, 'ㅓ': 23, 'ㅔ': 24, 'ㅕ': 25, 'ㅖ': 26, 'ㅗ': 27, 'ㅘ': 28, 'ㅙ': 29, 'ㅛ': 30, 'ㅜ': 31, 'ㅝ': 32, 'ㅞ': 33, 'ㅟ': 34, 'ㅠ': 35, 'ㅡ': 36, 'ㅢ': 37, 'ㅣ': 38}\n"
     ]
    }
   ],
   "source": [
    "img_dir = \"./data/jamo\"\n",
    "img_data = dsets.ImageFolder(img_dir, transforms.Compose([\n",
    "            transforms.Grayscale(),\n",
    "# https://pytorch.org/docs/stable/torchvision/transforms.html\n",
    "#           Data Augmentation\n",
    "#           transforms.RandomRotation(15)\n",
    "#           transforms.CenterCrop(28),\n",
    "#           transforms.Lambda(lambda x: x.rotate(15)),\n",
    "    \n",
    "#           Data Nomalization\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "# Normalize a tensor image with mean and standard deviation.\n",
    "# Given mean: (M1,...,Mn) and std: (S1,..,Sn) for n channels,\n",
    "# this transform will normalize each channel of the input torch.\n",
    "# *Tensor i.e. input[channel] = (input[channel] - mean[channel]) / std[channel]\n",
    "            ]))\n",
    "\n",
    "#https://pytorch.org/docs/stable/torchvision/transforms.html\n",
    "\n",
    "print(img_data.classes)\n",
    "print(img_data.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, train_ratio, batch_size, stratify) :\n",
    "    \n",
    "    length = len(data)\n",
    "    \n",
    "    cut = int(len(data)*train_ratio)\n",
    "    train_indices = np.random.shuffle(np.random.permutation(np.arange(length))[:cut])\n",
    "    test_indices = np.random.shuffle(np.random.permutation(np.arange(length))[cut:])\n",
    "        \n",
    "    if stratify :\n",
    "        \n",
    "        count = [0]*len(img_data.classes)\n",
    "        for _, label in img_data :\n",
    "            count[label] += 1\n",
    "\n",
    "        weight = []    \n",
    "        for i, (_, label) in enumerate(img_data) :\n",
    "            weight.append(1/ count[label])\n",
    "        weight = np.array(weight)\n",
    "        \n",
    "        train_indices = np.random.choice(length, cut, p=weight/sum(weight), replace=False)\n",
    "        test_indices = np.array(list(set(range(length)) - set(train_indices)))\n",
    "        \n",
    "    train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=False, sampler = torch.utils.data.SubsetRandomSampler(train_indices), drop_last = True)\n",
    "    test_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=False, sampler = torch.utils.data.SubsetRandomSampler(test_indices), drop_last = True)\n",
    "\n",
    "    return train_loader, test_loader, len(train_indices), len(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader, train_num, test_num = train_test_split(img_data, 0.8, batch_size, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.2 Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(1,16,5),\n",
    "            nn.ReLU(),\n",
    "            #Dropout\n",
    "            nn.Dropout2d(0.5),\n",
    "            nn.Conv2d(16,32,5),\n",
    "            #Batch Nomalization\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(32,64,5),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "        \n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(64*5*5,500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500,39)\n",
    "        )\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "#                 Weight Initialization\n",
    "#                 init.xavier_normal(m.weight.data)\n",
    "                init.kaiming_normal_(m.weight.data)\n",
    "                m.bias.data.fill_(0)\n",
    "        \n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.kaiming_normal_(m.weight.data)\n",
    "                m.bias.data.fill_(0)                \n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.layer(x)\n",
    "        out = out.view(batch_size,-1)\n",
    "        out = self.fc_layer(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "model = CNN().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss() # Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Momentum & Weight Regularization(L2)\n",
    "# optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model() :\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "\n",
    "        images = images.cuda()\n",
    "        outputs = model(images)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.cuda()).sum()\n",
    "\n",
    "    print('Accuracy of test images: %f %%' % (100 * float(correct) / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], lter [100/224], Loss: 0.6927\n",
      "Accuracy of test images: 78.410714 %\n",
      "Epoch [1/50], lter [200/224], Loss: 0.5393\n",
      "Accuracy of test images: 85.928571 %\n",
      "Epoch [2/50], lter [100/224], Loss: 0.3914\n",
      "Accuracy of test images: 87.732143 %\n",
      "Epoch [2/50], lter [200/224], Loss: 0.2195\n",
      "Accuracy of test images: 93.517857 %\n",
      "Epoch [3/50], lter [100/224], Loss: 0.1025\n",
      "Accuracy of test images: 92.589286 %\n",
      "Epoch [3/50], lter [200/224], Loss: 0.3041\n",
      "Accuracy of test images: 93.875000 %\n",
      "Epoch [4/50], lter [100/224], Loss: 0.1127\n",
      "Accuracy of test images: 95.464286 %\n",
      "Epoch [4/50], lter [200/224], Loss: 0.1038\n",
      "Accuracy of test images: 96.071429 %\n",
      "Epoch [5/50], lter [100/224], Loss: 0.0819\n",
      "Accuracy of test images: 95.660714 %\n",
      "Epoch [5/50], lter [200/224], Loss: 0.0966\n",
      "Accuracy of test images: 96.232143 %\n",
      "Epoch [6/50], lter [100/224], Loss: 0.1411\n",
      "Accuracy of test images: 93.625000 %\n",
      "Epoch [6/50], lter [200/224], Loss: 0.0526\n",
      "Accuracy of test images: 96.142857 %\n",
      "Epoch [7/50], lter [100/224], Loss: 0.0925\n",
      "Accuracy of test images: 94.821429 %\n",
      "Epoch [7/50], lter [200/224], Loss: 0.0214\n",
      "Accuracy of test images: 97.035714 %\n",
      "Epoch [8/50], lter [100/224], Loss: 0.0166\n",
      "Accuracy of test images: 96.535714 %\n",
      "Epoch [8/50], lter [200/224], Loss: 0.0243\n",
      "Accuracy of test images: 97.267857 %\n",
      "Epoch [9/50], lter [100/224], Loss: 0.0352\n",
      "Accuracy of test images: 97.500000 %\n",
      "Epoch [9/50], lter [200/224], Loss: 0.0270\n",
      "Accuracy of test images: 97.517857 %\n",
      "Epoch [10/50], lter [100/224], Loss: 0.0233\n",
      "Accuracy of test images: 97.410714 %\n",
      "Epoch [10/50], lter [200/224], Loss: 0.0200\n",
      "Accuracy of test images: 97.375000 %\n",
      "Epoch [11/50], lter [100/224], Loss: 0.0329\n",
      "Accuracy of test images: 96.017857 %\n",
      "Epoch [11/50], lter [200/224], Loss: 0.0095\n",
      "Accuracy of test images: 97.571429 %\n",
      "Epoch [12/50], lter [100/224], Loss: 0.0158\n",
      "Accuracy of test images: 97.607143 %\n",
      "Epoch [12/50], lter [200/224], Loss: 0.0319\n",
      "Accuracy of test images: 97.571429 %\n",
      "Epoch [13/50], lter [100/224], Loss: 0.0185\n",
      "Accuracy of test images: 98.089286 %\n",
      "Epoch [13/50], lter [200/224], Loss: 0.0085\n",
      "Accuracy of test images: 97.928571 %\n",
      "Epoch [14/50], lter [100/224], Loss: 0.0632\n",
      "Accuracy of test images: 98.178571 %\n",
      "Epoch [14/50], lter [200/224], Loss: 0.0160\n",
      "Accuracy of test images: 97.714286 %\n",
      "Epoch [15/50], lter [100/224], Loss: 0.0043\n",
      "Accuracy of test images: 98.089286 %\n",
      "Epoch [15/50], lter [200/224], Loss: 0.0262\n",
      "Accuracy of test images: 98.142857 %\n",
      "Epoch [16/50], lter [100/224], Loss: 0.0098\n",
      "Accuracy of test images: 98.321429 %\n",
      "Epoch [16/50], lter [200/224], Loss: 0.0181\n",
      "Accuracy of test images: 98.089286 %\n",
      "Epoch [17/50], lter [100/224], Loss: 0.0062\n",
      "Accuracy of test images: 98.107143 %\n",
      "Epoch [17/50], lter [200/224], Loss: 0.0565\n",
      "Accuracy of test images: 98.285714 %\n",
      "Epoch [18/50], lter [100/224], Loss: 0.0052\n",
      "Accuracy of test images: 98.303571 %\n",
      "Epoch [18/50], lter [200/224], Loss: 0.0259\n",
      "Accuracy of test images: 97.589286 %\n",
      "Epoch [19/50], lter [100/224], Loss: 0.0142\n",
      "Accuracy of test images: 98.107143 %\n",
      "Epoch [19/50], lter [200/224], Loss: 0.0053\n",
      "Accuracy of test images: 97.678571 %\n",
      "Epoch [20/50], lter [100/224], Loss: 0.0028\n",
      "Accuracy of test images: 97.892857 %\n",
      "Epoch [20/50], lter [200/224], Loss: 0.0767\n",
      "Accuracy of test images: 98.089286 %\n",
      "Epoch [21/50], lter [100/224], Loss: 0.0081\n",
      "Accuracy of test images: 98.160714 %\n",
      "Epoch [21/50], lter [200/224], Loss: 0.0010\n",
      "Accuracy of test images: 97.928571 %\n",
      "Epoch [22/50], lter [100/224], Loss: 0.0017\n",
      "Accuracy of test images: 98.267857 %\n",
      "Epoch [22/50], lter [200/224], Loss: 0.0003\n",
      "Accuracy of test images: 98.125000 %\n",
      "Epoch [23/50], lter [100/224], Loss: 0.0015\n",
      "Accuracy of test images: 98.339286 %\n",
      "Epoch [23/50], lter [200/224], Loss: 0.0170\n",
      "Accuracy of test images: 98.303571 %\n",
      "Epoch [24/50], lter [100/224], Loss: 0.0105\n",
      "Accuracy of test images: 98.321429 %\n",
      "Epoch [24/50], lter [200/224], Loss: 0.0024\n",
      "Accuracy of test images: 98.035714 %\n",
      "Epoch [25/50], lter [100/224], Loss: 0.0059\n",
      "Accuracy of test images: 98.214286 %\n",
      "Epoch [25/50], lter [200/224], Loss: 0.0012\n",
      "Accuracy of test images: 98.250000 %\n",
      "Epoch [26/50], lter [100/224], Loss: 0.0106\n",
      "Accuracy of test images: 98.196429 %\n",
      "Epoch [26/50], lter [200/224], Loss: 0.0147\n",
      "Accuracy of test images: 98.125000 %\n",
      "Epoch [27/50], lter [100/224], Loss: 0.0121\n",
      "Accuracy of test images: 98.035714 %\n",
      "Epoch [27/50], lter [200/224], Loss: 0.0033\n",
      "Accuracy of test images: 98.196429 %\n",
      "Epoch [28/50], lter [100/224], Loss: 0.0024\n",
      "Accuracy of test images: 98.446429 %\n",
      "Epoch [28/50], lter [200/224], Loss: 0.0018\n",
      "Accuracy of test images: 98.535714 %\n",
      "Epoch [29/50], lter [100/224], Loss: 0.0053\n",
      "Accuracy of test images: 98.571429 %\n",
      "Epoch [29/50], lter [200/224], Loss: 0.0295\n",
      "Accuracy of test images: 98.375000 %\n",
      "Epoch [30/50], lter [100/224], Loss: 0.0019\n",
      "Accuracy of test images: 98.232143 %\n",
      "Epoch [30/50], lter [200/224], Loss: 0.0001\n",
      "Accuracy of test images: 98.589286 %\n",
      "Epoch [31/50], lter [100/224], Loss: 0.0028\n",
      "Accuracy of test images: 98.517857 %\n",
      "Epoch [31/50], lter [200/224], Loss: 0.0048\n",
      "Accuracy of test images: 97.875000 %\n",
      "Epoch [32/50], lter [100/224], Loss: 0.0089\n",
      "Accuracy of test images: 98.035714 %\n",
      "Epoch [32/50], lter [200/224], Loss: 0.0302\n",
      "Accuracy of test images: 98.428571 %\n",
      "Epoch [33/50], lter [100/224], Loss: 0.0003\n",
      "Accuracy of test images: 97.964286 %\n",
      "Epoch [33/50], lter [200/224], Loss: 0.0010\n",
      "Accuracy of test images: 97.625000 %\n",
      "Epoch [34/50], lter [100/224], Loss: 0.0245\n",
      "Accuracy of test images: 98.250000 %\n",
      "Epoch [34/50], lter [200/224], Loss: 0.0066\n",
      "Accuracy of test images: 98.517857 %\n",
      "Epoch [35/50], lter [100/224], Loss: 0.0001\n",
      "Accuracy of test images: 98.535714 %\n",
      "Epoch [35/50], lter [200/224], Loss: 0.0001\n",
      "Accuracy of test images: 98.500000 %\n",
      "Epoch [36/50], lter [100/224], Loss: 0.0037\n",
      "Accuracy of test images: 98.678571 %\n",
      "Epoch [36/50], lter [200/224], Loss: 0.0021\n",
      "Accuracy of test images: 98.267857 %\n",
      "Epoch [37/50], lter [100/224], Loss: 0.0003\n",
      "Accuracy of test images: 98.625000 %\n",
      "Epoch [37/50], lter [200/224], Loss: 0.0008\n",
      "Accuracy of test images: 98.571429 %\n",
      "Epoch [38/50], lter [100/224], Loss: 0.0002\n",
      "Accuracy of test images: 98.625000 %\n",
      "Epoch [38/50], lter [200/224], Loss: 0.0255\n",
      "Accuracy of test images: 98.642857 %\n",
      "Epoch [39/50], lter [100/224], Loss: 0.0012\n",
      "Accuracy of test images: 98.232143 %\n",
      "Epoch [39/50], lter [200/224], Loss: 0.0352\n",
      "Accuracy of test images: 97.625000 %\n",
      "Epoch [40/50], lter [100/224], Loss: 0.0004\n",
      "Accuracy of test images: 98.589286 %\n",
      "Epoch [40/50], lter [200/224], Loss: 0.0081\n",
      "Accuracy of test images: 98.410714 %\n",
      "Epoch [41/50], lter [100/224], Loss: 0.0004\n",
      "Accuracy of test images: 98.607143 %\n",
      "Epoch [41/50], lter [200/224], Loss: 0.0033\n",
      "Accuracy of test images: 98.696429 %\n",
      "Epoch [42/50], lter [100/224], Loss: 0.0268\n",
      "Accuracy of test images: 98.553571 %\n",
      "Epoch [42/50], lter [200/224], Loss: 0.0000\n",
      "Accuracy of test images: 98.625000 %\n",
      "Epoch [43/50], lter [100/224], Loss: 0.0008\n",
      "Accuracy of test images: 98.642857 %\n",
      "Epoch [43/50], lter [200/224], Loss: 0.0003\n",
      "Accuracy of test images: 98.464286 %\n",
      "Epoch [44/50], lter [100/224], Loss: 0.0136\n",
      "Accuracy of test images: 98.017857 %\n",
      "Epoch [44/50], lter [200/224], Loss: 0.0007\n",
      "Accuracy of test images: 98.482143 %\n",
      "Epoch [45/50], lter [100/224], Loss: 0.0003\n",
      "Accuracy of test images: 98.392857 %\n",
      "Epoch [45/50], lter [200/224], Loss: 0.0008\n",
      "Accuracy of test images: 98.517857 %\n",
      "Epoch [46/50], lter [100/224], Loss: 0.0003\n",
      "Accuracy of test images: 98.392857 %\n",
      "Epoch [46/50], lter [200/224], Loss: 0.0008\n",
      "Accuracy of test images: 98.517857 %\n",
      "Epoch [47/50], lter [100/224], Loss: 0.0002\n",
      "Accuracy of test images: 98.446429 %\n",
      "Epoch [47/50], lter [200/224], Loss: 0.0006\n",
      "Accuracy of test images: 98.500000 %\n",
      "Epoch [48/50], lter [100/224], Loss: 0.0014\n",
      "Accuracy of test images: 98.750000 %\n",
      "Epoch [48/50], lter [200/224], Loss: 0.0002\n",
      "Accuracy of test images: 98.678571 %\n",
      "Epoch [49/50], lter [100/224], Loss: 0.0037\n",
      "Accuracy of test images: 98.607143 %\n",
      "Epoch [49/50], lter [200/224], Loss: 0.0005\n",
      "Accuracy of test images: 98.553571 %\n",
      "Epoch [50/50], lter [100/224], Loss: 0.0012\n",
      "Accuracy of test images: 98.642857 %\n",
      "Epoch [50/50], lter [200/224], Loss: 0.0003\n",
      "Accuracy of test images: 98.607143 %\n"
     ]
    }
   ],
   "source": [
    "# Learning Rate Scheduler\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "#scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma= 0.99)\n",
    "#scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[10,30,80], gamma= 0.1)\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma= 0.99)\n",
    "#scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    for i, (batch_images, batch_labels) in enumerate(train_loader):\n",
    "        \n",
    "        X = batch_images.cuda()\n",
    "        Y = batch_labels.cuda()\n",
    "\n",
    "        pre = model(X)\n",
    "        cost = loss(pre, Y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch [%d/%d], lter [%d/%d], Loss: %.4f'\n",
    "                 %(epoch+1, num_epochs, i+1, train_num//batch_size, cost.item()))\n",
    "            test_model()\n",
    "            model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
